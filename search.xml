<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[B Tree]]></title>
    <url>%2F2017%2F05%2F21%2Fbtree%2F</url>
    <content type="text"><![CDATA[B-树与B+树背景 动态查找树：BST，AVL，红黑树，B树，B+树等。前三种属于二叉查找树，查找效率与树的深度d有关，降低树的高度可以提升查找效率！在实际大规模存储过程中，数据量往往很大，树存储数据量有限，所以造成树的深度很大，而且也很直接放在内存中直接处理。所以导致树的深度很大，多次查找硬盘I／O过于频繁，查询效率较低，所以降低树的深度很重要，那么就需要采用多叉树结构！而B树使得树深度较低，所以查找效率较高！ 磁盘 磁盘作为外存储器，读取效率比内存慢很多，它的结构如下图所示： 磁盘有多个盘片组成，盘片装在一个主轴上，并绕主轴高速旋转，当磁道在读/写头(又叫磁头) 下通过时，就可以进行数据的读 / 写了，每个盘面有一个磁头，它可以从一个磁到移到另一个磁道。所有磁头都装在同一个动臂上，因此不同盘面上的所有磁头都是同时移动的(行动整齐划一)。当盘片绕主轴旋转的时候，磁头与旋转的盘片形成一个圆柱体。各个盘面上半径相同的磁道组成了一个圆柱面，我们称为柱面 。因此，柱面的个数也就是盘面上的磁道数。磁盘上数据必须用一个三维地址唯一标示：柱面号、盘面号、块号(磁道上的盘块)。读/写磁盘上某一指定数据需要下面3个步骤：(1) 首先移动臂根据柱面号使磁头移动到所需要的柱面上，这一过程被称为定位或查找 。(2) 如上图11.3中所示的6盘组示意图中，所有磁头都定位到了10个盘面的10条磁道上(磁头都是双向的)。这时根据盘面号来确定指定盘面上的磁道。(3) 盘面确定以后，盘片开始旋转，将指定块号的磁道段移动至磁头下。访问某一具体信息，由3部分时间组成：● 查找时间(seek time) Ts: 完成上述步骤(1)所需要的时间。这部分时间代价最高，最大可达到0.1s左右。● 等待时间(latency time) Tl: 完成上述步骤(3)所需要的时间。由于盘片绕主轴旋转速度很快，一般为7200转/分(电脑硬盘的性能指标之一）因此一般旋转一圈大约0.0083s。● 传输时间(transmission time) Tt: 数据通过系统总线传送到内存的时间，一般传输一个字节(byte)大概0.02us=2*10^(-8)s磁盘读取数据是以盘块(block)为基本单位的。位于同一盘块中的所有数据都能被一次性全部读取出来。而磁盘IO代价主要花费在查找时间Ts上。因此我们应该尽量将相关信息存放在同一盘块，同一磁道中。或者至少放在同一柱面或相邻柱面上，以求在读/写信息时尽量减少磁头来回移动的次数，避免过多的查找时间Ts B-树B-树是一种多路查找树，能极大降低树的深度，许多数据库系统都一般使用B树或者B树的各种变形结构。B-树的定义如下：一颗m阶的b-树结构1）若根结点不是叶子结点，则至少有2个孩子，最多含有m个孩子（m&gt;=2）（特殊情况：没有孩子的根结点，即根结点为叶子结点，整棵树只有一个根节点）2）除根结点和叶子结点外，其它每个结点至少有[ceil(m / 2)]个孩子，最多含有m个孩子（其中ceil(x)是一个取上限的函数）；3）所有叶子结点都出现在同一层，叶子结点不包含任何关键字信息(可以看做是外部接点或查询失败的接点，实际上这些结点不存在，指向这些结点的指针都为null)4）每个非终端结点中包含有n个关键字信息： (n，P0，K1，P1，K2，P2，……，Kn，Pn)。其中： a) Ki (i=1…n)为关键字，且关键字按顺序升序排序K(i-1)&lt; Ki b) Pi为指向子树根的接点，且指针P(i-1)指向子树种所有结点的关键字均小于Ki，但都大于K(i-1) c) 关键字的个数n必须满足： [ceil(m / 2)-1]&lt;= n &lt;= m-1 一颗3阶B树示例如下图所示： 首先节点定义为：12345678910typedef struct &#123; /*文件数*/ 关键字个数 int file_num; /*文件名(key)*/ 即 key char * file_name[max_file_num]; /*指向子节点的指针*/ 孩子指针 BTNode * BTptr[max_file_num+1]; /*文件在硬盘中的存储位置*/ 实际数据磁盘地址 FILE_HARD_ADDR offset[max_file_num];&#125;BTNode; B树包含N个关键字时，最大深度为：h=log┌m/2┐((N+1)/2 )+1，每一个非叶子结点含有ceil（m／2）个孩子 B-树的插入过程： 插入一个元素时，首先在B树中是否存在，如果不存在，即在叶子结点处结束，然后在叶子结点中插入该新的元素，注意：如果叶子结点空间足够，这里需要向右移动该叶子结点中大于新插入关键字的元素，如果空间满了以致没有足够的空间去添加新的元素，则将该结点进行“分裂”，将一半数量的关键字元素分裂到新的其相邻右结点中，中间关键字元素上移到父结点中（当然，如果父结点空间满了，也同样需要“分裂”操作），而且当结点中关键元素向右移动了，相关的指针也需要向右移。如果在根结点插入新元素，空间满了，则进行分裂操作，这样原来的根结点中的中间关键字元素向上移动到新的根结点中，因此导致树的高度增加一层。 以一颗5阶B-树来展示插入过程：插入以下字符字母到一棵空的B 树中（非根结点关键字数小了（小于2个）就合并，大了（超过4个）就分裂）：C N G A H E K Q M F W L T Z D P R X Y S （1）首先根节点空间充足，直接插入4个节点 （2）插入H时，结点发现空间不够，以致将其分裂成2个结点，移动中间元素G上移到新的根结点中 （3）插入E,K,Q时，不需要任何分裂操作 （4）插入M需要一次分裂，注意M恰好是中间关键字元素，以致向上移到父节点中 （5）插入F,W,L,T不需要任何分裂操作 （6）插入Z时，最右的叶子结点空间满了，需要进行分裂操作，中间元素T上移到父节点中 （7）插入D时，导致最左边的叶子结点被分裂，D恰好也是中间元素，上移到父节点中，然后字母P,R,X,Y陆续插入不需要任何分裂操作 （8）当插入S时，含有N,P,Q,R的结点需要分裂，把中间元素Q上移到父节点中，但是情况来了，父节点中空间已经满了，所以也要进行分裂，将父节点中的中间元素M上移到新形成的根结点中，注意以前在父节点中的第三个指针在修改后包括D和G节点中 删除操作：找B树中需删除的元素,如果该元素在B树中存在，则将该元素在其结点中进行删除，如果删除该元素后，首先判断该元素是否有左右孩子结点，如果有，则上移孩子结点中的某相近元素(“左孩子最右边的节点”或“右孩子最左边的节点”)到父节点中，然后是移动之后的情况；如果没有，直接删除后，移动之后的情况删除元素，移动相应元素之后，如果某结点中元素数目（即关键字数）小于ceil(m/2)-1，则需要看其某相邻兄弟结点是否丰满（结点中元素个数大于ceil(m/2)-1）（还记得第一节中关于B树的第5个特性中的c点么?： c)除根结点之外的结点（包括叶子结点）的关键字的个数n必须满足： （ceil(m / 2)-1）&lt;= n &lt;= m-1。m表示最多含有m个孩子，n表示关键字数。在本小节中举的一颗B树的示例中，关键字数n满足：2&lt;=n&lt;=4），如果丰满，则向父节点借一个元素来满足条件；如果其相邻兄弟都刚脱贫，即借了之后其结点数目小于ceil(m/2)-1，则该结点与其相邻的某一兄弟结点进行“合并”成一个结点。 下面看删除H,T,R,E过程： （9）首先删除元素H，当然首先查找H，H在一个叶子结点中，且该叶子结点元素数目3大于最小元素数目ceil(m/2)-1=2，则操作很简单，咱们只需要移动K至原来H的位置，移动L至K的位置（也就是结点中删除元素后面的元素向前移动） （10）删除T,因为T没有在叶子结点中，而是在中间结点中找到，咱们发现他的继承者W(字母升序的下个元素)，将W上移到T的位置，然后将原包含W的孩子结点中的W进行删除，这里恰好删除W后，该孩子结点中元素个数大于2，无需进行合并操作 （11）删除R，R在叶子结点中,但是该结点中元素数目为2，删除导致只有1个元素，已经小于最小元素数目ceil(5/2)-1=2,而由前面我们已经知道：如果其某个相邻兄弟结点中比较丰满（元素个数大于ceil(5/2)-1=2），则可以向父结点借一个元素，然后将最丰满的相邻兄弟结点中上移最后或最前一个元素到父节点中（有没有看到红黑树中左旋操作的影子?），在这个实例中，右相邻兄弟结点中比较丰满（3个元素大于2），所以先向父节点借一个元素W下移到该叶子结点中，代替原来S的位置，S前移；然后X在相邻右兄弟结点中上移到父结点中，最后在相邻右兄弟结点中删除X，后面元素前移。 （12）删除E， 删除后会导致很多问题，因为E所在的结点数目刚好达标，刚好满足最小元素个数（ceil(5/2)-1=2）,而相邻的兄弟结点也是同样的情况，删除一个元素都不能满足条件，所以需要该节点与某相邻兄弟结点进行合并操作；首先移动父结点中的元素（该元素在两个需要合并的两个结点元素之间）下移到其子结点中，然后将这两个结点进行合并成一个结点。所以在该实例中，咱们首先将父节点中的元素D下移到已经删除E而只有F的结点中，然后将含有D和F的结点和含有A,C的相邻兄弟结点进行合并成一个结点然后发现父节点只包含一个元素G，没达标（因为非根节点包括叶子结点的关键字数n必须满足于2=&lt;n&lt;=4，而此处的n=1），这是不能够接受的。如果这个问题结点的相邻兄弟比较丰满，则可以向父结点借一个元素。假设这时右兄弟结点（含有Q,X）有一个以上的元素（Q右边还有元素），然后咱们将M下移到元素很少的子结点中，将Q上移到M的位置，这时，Q的左子树将变成M的右子树，也就是含有N，P结点被依附在M的右指针上。所以在这个实例中，咱们没有办法去借一个元素，只能与兄弟结点进行合并成一个结点，而根结点中的唯一元素M下移到子结点，这样，树的高度减少一层。 在看一个删除操作：5阶B树，删除C（a）先删除元素C的右子结点中的D元素上移到C的位置，但是出现上移元素后，只有一个元素的结点的情况。又因为含有E的结点，其相邻兄弟结点才刚脱贫（最少元素个数为2），不可能向父节点借元素，所以只能进行合并操作，于是这里将含有A,B的左兄弟结点和含有E的结点进行合并成一个结点。（b）这样又出现只含有一个元素F结点的情况，这时，其相邻的兄弟结点是丰满的（元素个数为3&gt;最小元素个数2），这样就可以想父结点借元素了，把父结点中的J下移到该结点中，相应的如果结点中J后有元素则前移，然后相邻兄弟结点中的第一个元素（或者最后一个元素）上移到父节点中，后面的元素（或者前面的元素）前移（或者后移）；注意含有K，L的结点以前依附在M的左边，现在变为依附在J的右边。这样每个结点都满足B树结构性质 B+树特点：（1）有n棵子树的结点中含有n-1 个关键字 （2）所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接。 (而B 树的叶子节点并没有包括全部需要查找的信息) （3）所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。 (而B 树的非终节点也包含需要查找的有效信息) 优点：（1）B+-tree的磁盘读写代价更低 B+-tree的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B 树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。（2）B+-tree的查询效率更加稳定由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。（3）B+树支持范围查询 B+树只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作（或者说效率太低） 总结：B树：有序数组+平衡多叉树；B+树：有序数组链表+平衡多叉树； （1）对于单个查询，b树可能更早的返回数据，因为内节点也存储了数据信息，而b+树需要查到叶子结点，但是b+树节点需要更少的空间所以磁盘I／O会少一点，除此之外，b+树支持范围查询和扫描，所以更加方便！（2）b树和b+树在内存中没有任何优势，不如AVL和红黑树，但是在磁盘降低了树的深度，其I／O次数明显减少，所以大大降低了查询时间，被广泛用于数据库索引（Mysql）。]]></content>
      <categories>
        <category>Basic</category>
      </categories>
      <tags>
        <tag>DataStructure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Clone]]></title>
    <url>%2F2017%2F05%2F21%2Fclone%2F</url>
    <content type="text"><![CDATA[Java Cloneclone是Object类下的一个方法，用于产生一个创建一个新的对象副本。clone主要分为深复制和浅复制，下面我们分别介绍clone如何工作，以及如何实现深复制和浅复制。克隆对象 clone方法会返回原始对象的一个副本，一个良好的clone准则往往满足以下三个基本原则： （1）a.clone()!=a 克隆对象与原对象在heap上是两个独立的对象 （2）a.clone().getClass()==a.getClass() 克隆的对象必须与原对象类型一致 （3）a.clone().equals(a) 两个对象要想等 这些并非强制要求，为了达到第三个目的，可能要重写equals方法。 clone工作过程 Object类提供了clone实现，它被声明为protect native，它的具体实现由本地代码完成，对象的复制通过super.clone()来完成。所以任何对象的复制最终通过一系列的调用到达Object的clone方法，它首先会检查当前类是否实现了Cloneable接口，如果没有实现则抛出CloneNotSupportted异常，该异常是一个受检异常。若该类实现了接口，则调用Object的clone方法创建一个拷贝给调用者。而这一过程通过创建一个新对象，然后将对象的各个域直接复制过来的，对于原始的类型和不可变类型这种方式没有任何问题，但对于可变的类型和引用类型，它们将指向相同的对象，所以在修改时容易相互影响。所以Object的clone是一种浅复制，必须覆盖clone方法来实现深复制。 Example：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package standard;/** * Created by fuyang on 2017/5/15. */public class Student implements Cloneable&#123; private int[] money; private int age; public Student(int[] money, int age) &#123; this.money = money; this.age = age; &#125; public int[] getMoney() &#123; return money; &#125; public int getAge() &#123; return age; &#125; public void setMoney(int money) &#123; this.money[0] = money; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; return new Student(money.clone(),this.age); // return super.clone(); &#125; public static void main(String[] args) &#123; Student student=new Student(new int[]&#123;100&#125;,25); try &#123; Student cloneStu=(Student) student.clone(); System.out.println(cloneStu.getMoney()[0]); student.setMoney(200); System.out.println(student.getMoney()[0]); System.out.println(cloneStu.getMoney()[0]); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;结果：100200100改为 super.clone();则：100200200 Tips： 克隆方法用于创建对象的拷贝，为了使用clone方法，类必须实现java.lang.Cloneable接口重写protected方法clone，如果没有实现Clonebale接口会抛出CloneNotSupportedException 在克隆java对象的时候不会调用构造器 java提供一种叫浅拷贝（shallow copy）的默认方式实现clone，创建好对象的副本后然后通过赋值拷贝内容，意味着如果你的类包含可变对象，那么原始对象和克隆都将指向相同的内部对象，这是很危险的，因为发生在可变的字段上任何改变将反应到原始对象和副本对象上。为了避免这种情况，重写clone()方法。]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AVL树]]></title>
    <url>%2F2017%2F05%2F20%2Favl%2F</url>
    <content type="text"><![CDATA[AVL Tree定义：首先是BST，而且任何一个节点的左子树和右子树高度差不超过1AVL定义：123456789101112public class AvlTree&lt;T extends Comparable&lt;T&gt;&gt; &#123; private AvlTreeNode root; public AvlTree() &#123; &#125; private class AvlTreeNode&lt;T extends Comparable&lt;T&gt;&gt; &#123; private T key; private int height; private AvlTreeNode&lt;T&gt; left; private AvlTreeNode&lt;T&gt; right; AVL树在插入和删除时会改变它的平衡结构，具体的不平衡情况如下所示： LL：节点左子树的左子树的高度高 LR：节点左子树的右子树的高度高 RL：节点右子树的左子树的高度高 RR：节点右子树的右子树的高度高 AVL的旋转 为了保持平很需要进行旋转操作来保持平衡，4种不平衡情况具体的旋转操作情况如下： （1）LL与RR LL旋转操作比较简单，只需要将不平衡的节点k2向右旋转，使得其左孩子k1成为“根”节点，然后k2成为其右孩子，k1的右子树称为k2的左子树，此时树已经平衡了，最后把k1和k2的高度进行更新RR以此类似，只需要把k2向左旋转LL旋转：12345678public AvlTreeNode leftLeftRotation(AvlTreeNode &lt;T&gt;node) &#123; AvlTreeNode &lt;T&gt;left = node.left; node.left = left.right; left.right = node; node.height = Math.max(height(node.left), height(node.right)) + 1; left.height = Math.max(node.height, height(left.left)) + 1; return left;&#125; RR旋转：12345678public AvlTreeNode rightRightRotation(AvlTreeNode&lt;T&gt; node) &#123; AvlTreeNode &lt;T&gt;right = node.right; node.right = right.left; right.left = node; node.height = Math.max(height(node.left), height(node.right)) + 1; right.height = Math.max(node.height, height(right.right)) + 1; return right;&#125; （2）LR与RLLR的旋转稍微复杂一点，首先对不平衡节点k3的左孩子k1进行一次“RR”旋转，这样树变成了LL不平衡状态，再进行一次“LL”旋转即可达到平衡同样RL的旋转情况与之一一对应，先进行一次“LL”旋转然后进行一次“RR”旋转LR与RL旋转：123456789public AvlTreeNode leftRightRotation(AvlTreeNode &lt;T&gt;node)&#123; node.left=rightRightRotation(node.left); return leftLeftRotation(node);&#125;public AvlTreeNode rightLeftRotation(AvlTreeNode &lt;T&gt;node)&#123; node.right=leftLeftRotation(node.right); return rightRightRotation(node);&#125; 插入节点插入过程和BST一样，但它会导致树不平衡，所以需要旋转来维持树的平衡：递归查询插入点，然后判断是否平衡，并根据不平衡类型做相应的旋转1234567891011121314151617181920212223242526272829public AvlTreeNode insert(T key, AvlTreeNode &lt;T&gt;node)&#123; if(node==null)&#123; node=new AvlTreeNode(key); return node; &#125; if(node.key.compareTo(key)==0)&#123; throw new RuntimeException("节点值重复了"); &#125;else if(node.key.compareTo(key)&gt;0)&#123; node.left=insert(key,node.left); if(height(node.left)-height(node.right)&gt;1)&#123; if(node.left.key.compareTo(key)&gt;0)&#123; node= leftLeftRotation(node); &#125;else &#123; node= leftRightRotation(node); &#125; &#125; &#125;else &#123; node.right=insert(key,node.right); if(height(node.right)-height(node.left)&gt;1)&#123; if(node.right.key.compareTo(key)&lt;0)&#123; node=rightRightRotation(node); &#125;else &#123; node=rightLeftRotation(node); &#125; &#125; &#125; node.height=Math.max(height(node.left),height(node.right))+1; return node;&#125; 删除过程删除过程首先定位到删除的节点，找出最“接近”（左子树高则选择左子树最大节点，然后处理左子树使其平衡，然后递归向上判断平衡；同样对于右子树高的情况，先找出右子树最小的节点来替代当前点，然后处理右子树使其平衡，最后递归向上使其平衡）的节点来替换它，最后处理子树平衡再向上递归处理不平衡代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public AvlTreeNode remove(T key,AvlTreeNode &lt;T&gt;node)&#123; if(node==null||key==null)&#123; return null; &#125; if(node.key.compareTo(key)&gt;0)&#123; node.left=remove(key,node.left); if(height(node.right)-height(node.left)&gt;1)&#123; if(height(node.right.left)&gt;height(node.right.right))&#123; node=rightLeftRotation(node); &#125;else &#123; node=rightRightRotation(node); &#125; &#125; &#125;else if(node.key.compareTo(key)&lt;0)&#123; node.right=remove(key,node.right); if(height(node.left)-height(node.right)&gt;1)&#123; if(height(node.left.left)&gt;=height(node.left.right))&#123; node=leftLeftRotation(node); &#125;else &#123; node=leftRightRotation(node); &#125; &#125; &#125;else&#123; if(node.left==null)&#123; AvlTreeNode tmp=node; node=node.right; tmp.right=null; &#125; else if(node.right==null)&#123; AvlTreeNode tmp=node; node=node.left; tmp.left=null; &#125; else &#123; if(height(node.left)&gt;height(node.right))&#123; AvlTreeNode&lt;T&gt; tmp=node.left; while(tmp.right!=null)&#123; tmp=tmp.right; &#125; node.key=tmp.key; node.left=remove(tmp.key,node.left); &#125;else&#123; AvlTreeNode &lt;T&gt;tmp=node.right; while(tmp.left!=null)&#123; tmp=tmp.left; &#125; node.key=tmp.key; node.right=remove(tmp.key,node.right); &#125; &#125; &#125; if(node!=null) &#123; node.height = Math.max(height(node.left), height(node.right)) + 1; &#125; return node;&#125; 总结：AVL插入删除过程需要处理平衡，删除过程较复杂。所以效率比BST低，但是查询操作稳定为O(lgn)。]]></content>
      <categories>
        <category>Basic</category>
      </categories>
      <tags>
        <tag>DataStructure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用设计模式]]></title>
    <url>%2F2017%2F01%2F21%2Fdesign%2F</url>
    <content type="text"><![CDATA[适配器与外观模式适配器模式定义：将一个类的接口转化成客户期望的另一个接口，使得原本接口不兼容的类可以合作。适配器使用过程：（1）客户通过调用适配器的方法对适配器发出请求（2）适配器使用被适配者接口把请求转化成被适配者的一个或多个调用接口（3）客户接受调用的结果，并未察觉这是适配器起转换作用 适配器可以适配多个类，同时若一个系统存在新接口的同时也存在旧的接口，并且新旧接口都在使用，那么适配器可以同时实现2个接口，则适配器既可以当新的接口也可以当旧的接口使用。适配器结构图如下所示： 适配器模式分为对象适配器和类适配器2种模式：对象适配器使用了组合的方式，委托给被调用者来实现，同时对象适配器可以适配类的所有子类；类适配器使用了多继承的方式，适配器继承了适配者和被适配者，所以它不需要实现被适配者，必要时候也可以覆盖被适配者的行为，但在java中不支持多继承！ 适配器 VS 装饰者 VS 外观模式 装饰者 ：与责任相关，不改变原有的接口，加入新的责任和功能，可以包装多次 适配器 ：将接口转化为另一种接口，无需改变原有的代码 外观 ：让接口更简单，对子系统进行了封装 外观模式外观模式定义：提供了一个统一的接口，用来访问子系统的一群接口。 外观定义了一个高层接口，让子系统更容易使用而不会修改它，当然你也可以直接使用子系统。外观模式使得客户实现从子系统中解耦，当以后系统升级改变时，只需要修改外观代码而不用修改客户代码。其中重要的一点是：适配器和外观模式都可以使用多个类，差别在于适配器改变原有的接口来满足需求，而外观模式简化了接口来访问子系统。 最小知识原则：只和你的密友谈话，注意和你交互的类有哪些，不要将过多的类耦合在一起。 要求：对于一个对象，最好应该只调用以下范围的方法 （1）该对象本身 （2）作为方法的参数传递进来的对象 （3）对象的任何组件 （4）方法内创建和实例化的对象 装饰者模式解决的问题：开放-关闭原则（类应该对扩展开放，对修改关闭） 装饰者模式定义：动态的将责任附加到对象上，若要扩展功能，装饰者提供了比继承更有弹性的替代方案装饰者模式意味着一群装饰者类，这些类用来包装具体组件，装饰者反映出被装饰组件的类型，事实上他们具有相同的类型（实现统一接口或集成同一超类），同时装饰者可以在被装饰者行为前后加上自己的行为来达到特定的目的，装饰者一般对组件的客户是透明的，具体的结构如下图所示：其中Compoment是基本组件，ConcreteComponent是具体需要装饰的对象，Decorator是装饰者抽象类，ConcrereDecoratorA／B是具体的装饰者类，用来包装ConcreteComponent，他们都继承与Component。 以星巴克咖啡为例：有多种饮料和调料，如何来描述和计算价格，若采用继承机构将会出现大量的类并且难于维护（计算价格特别麻烦），采用装饰者模式的结构如下图所示： 同时jdk中的IO也是典型的装饰者模式，如下图所示： 装饰者模式缺点：虽然比继承更容易扩展，但是会导致设计中出现许多的小对象，如果过度使用会让程序较为复杂，难于理解。 工厂模式工厂模式定义： 定义了一个创建对象的接口，但由子类决定要实例化的类是哪一个。即工厂方法让类把实例化推迟到子类。另一种看法：工厂方法将生产知识封装进各个创建者，创建者和产品是一种平行的类层级，以生产pizza为例，层次结构如下图所示：抽象工厂模式定义： 提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定类。该模式使得客户不需要知道具体的产品是什么，客户从具体的产品中被解耦。以pizza为例：如下图所示 工厂模式 vs 抽象工厂模式工厂模式：利用继承方式，通过子类来实例化具体的产品抽象工厂模式：利用组合方式，创建一个创建产品的抽象类，该类型子类定义了产品被产生的方法，然后实例化该工厂来产生具体的产品 观察者模式OO原则（1）封装变化（2）多用组合（几个对象协同工作），少用继承（3）针对接口编程，不针对实现编程（4）为交互对象之间的松耦合设计不断努力 观察者模式定义 定义对象之间的一对多耦合，这样以来，当一个对象的状态变化时，它的所有依赖者都能收到通知并自动更新该模式主要包含2部分：主题Subject、观察者Observer，主题负责提供对象的状态，增加删除观察者，并把对象的变化状态通知给观察者，具体的模式信息如下图所示： 以气象发布战为力例子，模式设计图如上所示：weatherData实现Subject接口，实现register、remove（list持有对观察者的引用）、notify（调用所有观察者update方法通知他们）三个主要方法，CurrentCondition实现Observer借口实现update方法。jdk中java.util.Observable java.util.Observer分别充当了主题和观察者角色，所以在实现该模式时无需自己实现细节，可以利用jdk来实现自己的观察者模式。 jdk观察者模式缺点：（1）Observable是一个抽象类而不是借口，应该多使用接口而非抽象类，不利于扩展（2）setChanged是一个protected方法，只能继承observable，否则不能通知观察者，不够灵活 可以借鉴jdk思想实现自己的通知方式，灵活使用观察者模式。 代理模式代理模式的结构如下图： 代理类Proxy和被代理类RealSubject都实现了同一接口，proxy负责realSubject的访问和控制。 JAVA中的代理RMI RMI使用步骤：（1）制作远程接口：扩展java.rmi.Remote所有方法都抛出异常RemoteException，确定变量和返回值都是可序列化的（2）制作远程实现：实现远程接口，构造一个不带参数构造函数并声明RemoteException，利用rmi registry注册此服务（3）利用rmic产生stub、skeleton：在远程实现类（非接口）执行rmic，执行rmiregistry，启动服务（注册对象）（4）启动rmi registry（rmiregistry，使得客户可以查到代理的位置）（5）开始远程服务 注意点：（1）在启用远程服务前必须先启用rmiregistry（2）变量和返回值都必须是可序列化的，否则运行时会出错（3）客户在lookup代理时，必须有stub类（由rmic产生），否则stub对象无法被反序列化，客户端需要调用远程对象返回的序列化对象！（4）服务端游stub与skeleton类，需要stub是因为stub是真正服务对象的替身，当对象被绑定时，真正绑定的对象是服务端的stub对象! JDK中的动态代理 Proxy与InvocationHandlerInvocationHandler起辅助作用，将proxy产生的代理类请求交给真正对象去处理，具体的结构图如下所示： 迭代器与组合模式迭代器模式定义：提供一种方法顺序访问一个聚合对象中的各个元素，而又不暴露其内部的表示！迭代器将元素游走遍历的职责交给迭代器，而不是聚合对象，这样简化了聚合接口的实现，让责任各得其所。 迭代器结构图如下所示： 单一职责：一个类应该只有一个引起变化的原因 尽量让每个类保持单一责任 组合模式定义：允许你将对象组合成树形结构来表现“整体／部分”层次结构。组合能让客户以一致的方式处理个别对象以及对象组合（处理时忽略对象组合和个别对象之间的差异。 组合模式往往需要一个抽象类，类中的方法对于叶子结点和组合节点不同，有些方法适用于叶子结点，而有些节点适用于组合节点，所以在处理时根据情况覆盖抽象类方法，有时候还需要处理异常情况，否则需要进行类型判断对用户不再透明！ 单例模式单例模式定义：只能创建一个对象，保证线程安全，提供全局访问点注意点：线程安全、效率、私有构造函数、静态对象 方法：急切加载 、double-check(voliate)、枚举、静态内部类(静态私有内部类，final私有staic变量)推荐后两者 状态模式定义：允许对象在内部状态改变时改变它的行为，对象看起来好像修改了它的类！使用方法：（1）定义一个State接口，每一个接口都有一个对应的方法（2）为系统中每一个状态实现State接口实现状态类，这些状态类负责相应状态下系统的行为（3）将动作委托到状态类 系统状态可以被多个Context共享，将状态设计为静态变量 状态模式结构图如下所示： 模版方法模式定义：在一个方法中定义一个算法的骨架，而将一些步骤延迟到子类中。模版方法使得之类可以在不改变算法结构的情况下，重新定义算法中的某些步骤，即由子类实现算法的部分实现！JDK中Arrays.sort方法中comparable将compareTo方法的实现交由子类实现，是一种模版方法！ 一般情况下，我们将抽象类中的算法的骨架设计为final类型的方法防止子类去修改，另外，可以在抽象类中将可选方法设计为hook（钩子）方法，子类可以选择覆盖来达到某种目的。 系统结构图： 好莱坞原则：别调用我们，我们会调用你！ 好莱坞原则：高层组件对底层组件的原则：别调用我，我会调用你 模版方法模式 VS 策略模式都是封装算法，模版方法使用了继承，由子类去实现算法某一部分细节；策略模式使用了组合，用委托决定采用哪一个行为 命令模式命令模式定义：将请求封装为命令对象，以便来使用不同的请求，队列或日志来参数化其他对象。命令模式也支持撤销操作。命令对象在特定接受者上绑定一组动作来封装一个请求，命令是通过将动作和接受者绑定在一起做到的，命令对象通常只暴露一个execute方法，该方法被调用时，接受者就会进行相关的操作。从表面看，调用者不知道哪个接受者进行了哪些动作，从而通过命令对象将调用者和接受者进行了解耦。 命令模式的用途：命令可以讲运算块打包（一组动作和一个接受者），然后传来传去。命令对象甚至可以在不同的线程中被调用，所以它可以用来：（1）日程安排（2）线程池（3）工作队列 命令模式将发出请求的对象和执行请求的对象解耦，这两者之间是通过命令对象进行沟通的，命令对象封装了接受者和一组动作，命令支持撤销，通过宏命令（多组命令）可以对简单命令进行扩展。命令用于线程队列、日志系统、事物系统等。 Java代码 : https://github.com/lifeloner/designPattern]]></content>
      <categories>
        <category>Design</category>
      </categories>
      <tags>
        <tag>Common</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lock与Synchronized]]></title>
    <url>%2F2017%2F01%2F09%2Flock%2F</url>
    <content type="text"><![CDATA[Java Synchronized与Lockjava中通过锁实现同步的方式主要有2种：通过synchronized关键字和显示的lock。1.synchronized其本质是对对象进行加锁，java中每一个对象都有内置锁，synchronized在修饰方法时也是对当前对象（this所指对象）进行加锁，对static方法加锁时是对该类进行加锁（类的class对象），所以对类的实例加锁和对类加锁互不影响。synchronized同步块是一种监视锁，反编译后可以看到monitor和exit monitor同步块，该区域内同一时刻只允许一个线程访问。注意加锁的粒度是线程而不是对象，jvm会记录线程获取锁的次数，当线程获取当前对象的内置锁时再进入同一对象的同步块时该线程获取次数会＋1，在该次数减为0之前其他线程无法获取当前锁，所以synchronized是可重入锁。 2.lock显示的lock也是可重入锁，在lock和unlock之间代码块受锁的保护。lock相比synchronized更灵活，提供了lock、try lock、lockInterruptibly等多种灵活的方式。其中lock（）和synchronized一样是不可中断的阻塞方法，而try lock是非阻塞的，加锁成功直接返回true，否则反回false，try lock也可以带一个时间参数，如果在规定的时间获取锁返回true，否则直接退出反回false，在等待期间是可响应中断的，lockInterruptibly是阻塞可中断的。 3.synchronized的继承性synchronized修饰的方法是不可继承的，这主要体现在：子类的方法不具有synchronized性质，若子类没有复写方法，同步依靠父类来提供；若子类复写了方法则该方法不具有同步特性。123456789101112131415161718192021222324252627282930313233343536373839404142package com.study.thread;/** * Created by fuyang on 16/7/28. */public class SuperClass &#123; public synchronized void methodOne()&#123; System.out.println("super method_one"); try &#123; Thread.sleep(6000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;package com.study.thread;/** * Created by fuyang on 16/7/28. */public class ChildClass extends SuperClass &#123; public void testMethod()&#123; new Thread(new Runnable() &#123; @Override public void run() &#123; methodOne(); &#125; &#125;).start(); &#125; public void methodOne()&#123; System.out.println("child method_one"); super.methodOne(); &#125; public static void main(String[] args) &#123; ChildClass childClass=new ChildClass(); childClass.testMethod(); childClass.testMethod(); &#125;&#125; 两个线程都会执行methodOne方法，但同时只有一个线程能执行父类的methodOne方法。所以子类一方面可以依靠父类提供同步保证，若复写了父类的方法则需要自己提供同步机制。 4.死锁问题线程在获取锁时，执行顺序不当往往会造成死锁，尤其在一个同步块中调用了另一个方法，而该方法中也有锁相关的操作，这种情况下存在潜在的死锁风险且不容易发现，synchronized在死锁时无法解决只能强制退出应用，下面是一个实例：123456789101112131415161718192021222324252627282930313233343536373839404142package com.study.thread;/** * Created by fuyang on 16/7/19. */public class DeadLockSynchronized &#123; public static void main(String[] args) &#123; Object a=new Object(); Object b=new Object(); new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (a)&#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (b)&#123; System.out.println(Thread.currentThread().getName()+" get a and b lock"); &#125; &#125; &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized (b) &#123; try &#123; Thread.sleep(600); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (a) &#123; System.out.println(Thread.currentThread().getName() + " get a and b lock"); &#125; &#125; &#125; &#125;).start(); System.out.println(Thread.currentThread().getName()+" finshed"); &#125;&#125; 使用lock能更灵活的避免死锁问题，可以尝试一次性申请所有锁，若失败则释放所有锁再重新尝试，代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.study.thread;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * Created by fuyang on 16/8/6. */public class DealLock &#123; public void testDeadLock(Lock one, Lock two, String a, String b, int time) &#123; while (true) &#123; if (one.tryLock()) &#123; try &#123; System.out.println(Thread.currentThread().getName() + " get lock " + a); Thread.sleep(600); if (two.tryLock()) &#123; try &#123; System.out.println(Thread.currentThread().getName() + " get lock " + b); return; &#125; finally &#123; two.unlock(); System.out.println(Thread.currentThread().getName() + " release lock " + b); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; one.unlock(); System.out.println(Thread.currentThread().getName() + " release lock " + a); &#125; &#125; try &#123; Thread.sleep(time * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + " fail and retry"); &#125; &#125; public static void main(String[] args) &#123; DealLock dealLock = new DealLock(); Lock one = new ReentrantLock(); Lock two = new ReentrantLock(); new Thread(new Runnable() &#123; @Override public void run() &#123; dealLock.testDeadLock(one, two, "one", "two", 2); &#125; &#125;, "thread_one").start(); new Thread(new Runnable() &#123; @Override public void run() &#123; dealLock.testDeadLock(two, one, "two", "one", 3); &#125; &#125;, "thread_two").start(); &#125;&#125; 结果如下：12345678910111213141516Connected to the target VM, address: '127.0.0.1:58776', transport: 'socket'thread_one get lock onethread_two get lock twothread_one release lock onethread_two release lock twothread_one fail and retrythread_one get lock onethread_one get lock twothread_one release lock twothread_one release lock onethread_two fail and retrythread_two get lock twothread_two get lock onethread_two release lock onethread_two release lock twoDisconnected from the target VM, address: '127.0.0.1:58776', transport: 'socket' 所以，在使用锁时一定要检查代码，考虑死锁的可能性，尤其注意锁的获取顺序。另外，synchronized的性能不如lock，若仅仅只是用来保证数据一致性而没有其他特殊要求，还是建议使用synchronized，jdk在每一个版本中都在不断优化内置锁的性能，所以它们差别很小，除非为了灵活性或其他需求而使用lock，使用lock时需要养成好习惯讲unlock写在finally语句块中防止程序异常也能够及时释放锁。]]></content>
      <categories>
        <category>Concurrent</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC]]></title>
    <url>%2F2017%2F01%2F09%2Fgc%2F</url>
    <content type="text"><![CDATA[Java内存模型与GC一 、Java内存区域 java与c＋＋很大的区别在于内存管理上，c＋＋中主要由程序员对内存进行申请和释放（new、delete／malloc、free），而java中内存交由JVM来管理，虽然这在一定程度上减少了java程序员的负担，但了解JVM内存管理、GC机制能够帮助我们写出高质量、高效率的代码、并能排除内存溢出、内存泄漏等常见问题，下面我们先了解一下java的内存区域。 JVM的内存区域划分如下图所示：1.程序计数器 程序计数器是一块较小的内存空间，用于记录线程的虚拟机字节码指令地址，程序的分支、循环、跳转、异常处理、以及线程切换都依赖与该计数器完成，它是线程私有的内存空间。 2.java虚拟机栈 虚拟机栈也是线程私有的，它描述了java方法执行的内存模型：每一个方法执行时都会创建一个栈帧用于存放局部变量表、操作数、方法出口等信息。每一个方法的调用和结束对应着栈帧入栈和出栈操作。局部变量表存放了基本的类型（boolean、byte、char、int、long、float、double），引用类型（reference，简单理解为对象的内存地址而不是对象本身），returnAddress（返回地址即虚拟机一条字节码指令，局部变量表大小在编译器确定，运行期间不会改变。该区域中可能出现StackOverFlowError（栈深度超过JVM允许深度），OutOfMemoryError（无法申请足够内存）。 3.本地方法栈 与虚拟机栈很类似，区别在于虚拟机栈对应的是java方法，而本地方法栈对应的是native方法服务（如c＋＋），JVM对本地方法栈的语言、数据结构没有要求，有的虚拟机（如HotSpot）甚至把虚拟机栈和本地方法栈合二为一统一管理。 4.java堆 这部分区域对大家最熟悉不过了，它是JVM管理的内存区域中最大的一块，存放着对象的实例，为所有线程共享，几乎所有的对象实例都在堆上分配内存（几乎而不是完全绝对）。堆也是GC回收的主要的区域，同样该区域也会抛出 OutOfMemoryError异常。 5.方法区 方法区也为所有线程共享，存放了虚拟机加载的类信息、常量、静态变量、编译后的代码等数据。运行时常量池是方法区的一部分，用于存放编译期的常量、符号引用、直接引用。方法区也会抛出OutOfMemoryError异常。 6.直接内存 直接内存不是JVM运行时数据区的一部分，也不是JVM定义的内存区域。但该区域也被频繁使用，可能导致OutOfMemoryError异常。NIO出现，引入了基于channel和buffer的I／O方式，它可以使用native函数库直接分配堆外内存，然后通过java堆中的directByteBuffer对象作为该内存的应用进行操作，以此来避免java堆和native堆来回复制数据，提高了性能。 下面我们以HotSpot虚拟机为例，了解一下创建对象时堆内存分配以及对象的访问过程。 （1）对象创建 当使用new创建一个对象时，虚拟机首先在方法区的常量池中定位到一个类的符号引用，检查符号引用的类是否被加载、解析、初始化，具体细节可以阅读java类加载机制相关知识点。在类加载后，需要在堆中分配内存，堆中的内存常常不是规整的往往存在内存碎片，所以需要使用“空闲列表”的方式来选择分配的地址。在分配内存时还需要注意线程安全，防止出现给对象A分配内存后没修改地址而对象B使用了相同的地址指针，所以可以采用2种办法：一是使用同步方式（虚拟机采用CAS的原子语义方式而不是锁），二是给每个线程分配一小块缓冲（TLAB），当线程使用完TLAB后再同步分配内存。对象内存分配后，JVM将内存空间初始化为零值（不包括对象头），接下来虚拟机将对象所属类的元数据信息、对象哈希码、gc分代年龄、对象锁信息放入对象内存的对象头中，这样JVM的对象初始化工作完成了，但在程序员看来对象的字段都还没初始化，接下来执行方法，按照构造函数要求对对象进行初始化，这样对象的整个初始化过程完成。 （2）对象访问 使用栈上的reference来操作堆中对象实例，应用定位和访问的方式有句柄和直接指针两种。 句柄方式需要在堆中申请一块额外的内存，reference存储了句柄的的地址，句柄优势在于对象实例被移动时只会改变句柄中实例数据指针，reference不用改变。直接指针方式优势在于定位速度快，省掉一次指针定位时间，hotspot虚拟机采用的直接指针方式，在大量对象访问情况下性能提升比较客观。 二、GC在学习GC前，我们首先需要明白几个问题：哪些内存需要回收？什么时候回收？怎么回收？ 1.对象的存活 判断对象是否死亡方式有多种，其中主要的方式有：引用计数法、可达性分析法。引用计数法：给对象添加一个引用计数器，每当有一个引用指向它，计数器加1，当引用失效，计数器减1，减为0则对象可以回收，但无法解决对象之间相互循环引用问题。可达性分析法：通过GC Roots对象为起点，往下搜索，经过的路径称为引用链，当对象通过引用链和GC Roots不可达时则可以回收。java中使用可达性分析算法来判断对象存活情况，java中常见的GC Roots有虚拟机栈引用的对象，方法区中常量、静态变量引用的对象、本地方法栈JNI引用的对象。 即使对象与GC Roots不可达，对象也并非必死不可，对象死亡至少经历2个标记过程，首先前面提到的不可达是第一次标记，然后进行一次筛选来确定是否需要执行finalize方法，若对象没有复写finalize方法或者之前已经执行过finalize，那么虚拟机将不再执行finalize方法。在第一次标记后，并需要执行finalize时，finalize是对象逃脱回收的最后机会，对象被放在F－Queue队列中，然后由一个低优先级的Finalizer线程执行对象finalize方法，如果对象在finalize中把自己引用（this）赋值给某个类变量或对象成员变量，那它将被移除被回收的集合，如果仍没有逃脱那基本将被JVM真正回收。一个对象可以在GC时逃脱，但只能逃脱一次，因为finalize只能执行一次。 GC并不仅仅发生在堆中，在方法区（hotspot中成为永久代）也会发生GC，只是回收效率较低。永久代中回收的内容主要有常量和类，一个常量没有任何地方使用就被认为是废弃的可以进行回收了，但类的判断要求严格的多，需要满足的条件有：类所有实例被回收；加载类的ClassLoader被收回手；Class对象没有在任何地方引用，无法通过反射访问类方法和字段。只有满足这3个要求，JVM才有可能（并不一定）回收该类。 2.GC算法 主要的gc算法有4种：标记－清除算法，复制算法，标记－整理算法，分代收集算法。 （1）标记－清除算法 标记－清除算法分为标记、清除2个阶段，首先对需要回收的对象进行标记，完成后统一回收标记的对象。它存在2个缺点：标记清除过程效率低，而且gc后存在大量不连续的内存碎片，导致以后分配大内存对象时内存不足，不得不触发另一次gc。 （2）复制算法 复制算法思想是把内存容量划分为大小相等的2块，每次使用其中一块，当内存不足时将存活的对象复制到另一块内存，这样就不存在内存碎片问题。但这样内存的使用率较低，没有充分利用内存，有些浪费。IBM经过研究表明，大部分对象（约98%）都是朝生夕死，并不需要按照1:1来划分，所以提出了eden，survivor（2个survivor，eden，suivivor比例为8:1）区域，将eden，survivor中对象移动另一块survivor中，最后清理掉eden，survivor区域，这样仅仅浪费了10%的内存，这也是hotspot默认的方式，当不能保证不超过10%内存大小对象存活时，需要依赖其他内存（老年代）进行分配担保。当存活对象较多时，回收效率较低，所以复制算法一般用于年轻代。 （3）标记－整理算法 对于老年代，提出了另一种方法：标记－整理算法，相比标记－清除算法，他不是直接对对象进行回收，而是把存活对象移动到一端，然后清理到边界以外的内存区域。 （4）分代收集算法 分代收集算法根据对象存活时间把对象分为年轻代、老年代，根据每个阶段采取不同的收集算法，一般对于年轻代大量的对象会死去，一般采用复制算法，对于老年代对象存活旅高，也没有分配担保，一般使用标记－清除，标记－整理算法。 3.HotSpot GC算法实现 在gc前，首先需要找出GC Roots节点以及引用链，一般作为GC Roots的节点主要有全局性引用（常量、类静态属性）以及执行上下文（栈帧的本地变量表）。在可达性分析时需要保证一致性，在枚举gc roots以及引用链时，需要停止java线程的执行（stop the world），不然对象引用关系在不断变化。在线程停止，检查寻找gc roots时，jvm并不需要一个一个的检查，hotspot使用了OopMap数据结构来达到这个目的，该数据结构记录了对象偏移量上是什么类型数据。 在OopMap帮助下，hotspot快速完成gc roots枚举，但hotspot没有为每个指令都生成OopMap，只是在特定的位置纪录了这些信息，这些位置被称为安全点。程序执行时并非在所有地方都可以停止下来gc，只能在安全点暂停下来，所以一般的安全点选取在方法调用、循环跳转、异常跳转。在gc时需要使所有的线程都运行到最近的安全点（safe point）上，所以有2种方案，一是抢先式中断：在gc时中断全部线程，若线程不在安全点上让他恢复运行到安全点上，另一种是主动式中断：不主动中断线程，通过设置标志，让线程主动轮询标志，发现中断标志后自己中断挂起，轮询位置刚好和安全点重合。 对于线程处于sleep、blocked时，线程无法执行到安全点时，需要使用安全域来解决。线程进入安全域（safe region）后，gc时不需要关注处于安全域状态的线程。当线程离开安全域时需要检查是否已经完成gc过程，若没有完成必须等到整改gc完成才能离开安全域。 4.垃圾收集器 垃圾收集器是gc算法的具体实现，jvm中的垃圾收集器很多，不同的版本、不同厂商虚拟机提供的垃圾收集器差异也很大，常见的gc收集器如下图所示：（1）Serial serial收集器是单线程的收集器，同时在gc时必须停止其他工作线程（stop the world），该收集器主要用于运行在client模式下的虚拟机。（2）ParNew parent是serial的多线程版本，其他策略与serial基本一致，是工作在server模式下的虚拟机首选的新生代收集器，能够与cms配合工作。在单cpu下它还不如serial的性能，但在多核下并发效果还是有不少提升。（3）Parallel Scavenge parallel scavenge收集器也是基于复制算法的新生代收集器， 相比其他收集器，它主要关注吞吐量（cpu运行用户代码时间与gc时间比例），cms主要关注了停顿时间适用于用户交互的程序，响应速度快，parallel scavenge使用了快速完成运算任务，不需要太多交互。parallel scavenge提供了2个参数用于控制吞吐量：－XX：MaxGCPauseMillis用于保障gc时间不超过设定值，－XX：GCTimeRatio设置gc时间最多占总时间比例，同时它该提供了－XX：＋UseAdaptiveSizePolicy虚拟机会根据系统情况自动调节gc时间和吞吐量，所以改收集器是一种吞吐量优先收集器。（4）Serial Old serial old也是一个单线程的老年代收集器，使用标记－整理算法，在client模式下配合serial工作，在server模式下与parallel scavenge搭配使用，或作为cos的后备收集器，在其发生concurrent mode failure备用。（5）parallel old 该收集器也适用了标记－整理算法，用于配合 parallel scavenge（无法与cms配合工作），因为serial old但线程收集能力较差无法利用多cpu处理能力。（6）CMS CMS收集器是以获取最短停顿时间为目标的收集器，能够加快响应速度，它是基于标记－清理算法，收集过程包含4个过程：初始标记、并发标记、重新标记、并发清除。1、3阶段需要stop the world，初始阶段标记gc roots直接关联的对象，速度较快，并发标记对gc roots进行追踪，重新标记修正并发标记中程序继续运行的变动，该阶段比初始标记慢但远比并发标记快。整个过程耗时的并发标记、清除可以与用户并发执行，所以停顿时间较短。 CMS作为优秀的收集器也有3个明显的缺陷，首先CMS对cpu资源敏感，并发时和工作线程一起运行占用cpu资源，导致程序执行速度变慢，吞吐量降低。其次，cms存在浮动垃圾，可能出现concurrent mode failure导致另一次full gc，原因在于cms在并发清除阶段程序还在运行，所以会有新的内存和垃圾出现，cms无法在这次gc中回收它们，由于在该阶段必须有足够的内存留给用户线程执行，所以cms不能等到老年代被使用完才gc，需要流出一部分空间在并发清除阶段给用户线程使用。如果这个阶段剩下内存不够用户线程使用，那么就出现了concurrent mode failure失败，jvm不得不使用serial old进行一次full gc，停顿用户线程进行gc，时间更长了。最后，cms基于标记－清除算法实现，存在内存碎片问题，所以cms提供了参数，在多少次gc后需要进行一次内存整理过程。（7）G1G1是当前gc中最前沿的研究成果，它不需要与其它垃圾收集器一起工作，相比其它收集器它的优势如下： 并行与并发：利用多cpu多核优势，减少stop the world时间，采用并发方式执行gc 分代回收：采用不同的方式处理新对象和旧对象，不需要配合其它收集器 空间整合：与cms的标记－清除不同，G1整体上基于标记－整理方式，局部上基于复制算法，都不会存在内存碎片问题 可预测停顿：不断能够减少停顿时间，还能建立可预测的时间模型，保证在M时间内gc时间不超过NG1将java堆划分为大小相同的区域（Region），保留了新时代老年代概念，他避免了在整个堆进行全区域gc，G1跟踪各个region的价值大小（gc时间、回收大小）维护一个优先级列表，回收价值最大的region，保证了高效的回收效率。在回收region时，对象的引用可能存在不同的region中，G1使用了Remembered Set来避免全表扫描引用关系，每一个region都有一个remembered set保存对象引用关系，G1收集过程分为4个步骤：初始标记、并发标记、最终标记、筛选回收。初始标记标记gc roots直接关联的对象，并发标记进行可达性分析，找出存活的对象，可与用户线程并发执行，最终标记修正并发阶段的变化，并将变化纪录在remembered set中，该过程需要停顿用户线程，最后筛选阶段根据region排序结果，按照优先级回收，该过程其实也可以做到并发执行，但仅仅回收一部分region速度较快，也没有太大必要。所以G1追求了低停顿，吞吐量没有改进。 5 内存分配和回收策略 （1）对象优先分配在eden区域中，eden区域空间不足将发起MinorGC （2）大对象直接进入老年代，jvm允许通过－XX：PretenureSize Threshold参数设置对象直接在老年代分配 （3）长期存活对象进入老年代，可设置－XX：MaxTenuring Threhold改变阈值 （4）动态对象年龄判断，jvm并不一定要求年龄达到阈值才能进入老年代，若survivor对象中相同年龄所有对象大小达到survivor一半，大于等于该年龄即可进入老年代 （5）空间分配担保，在Minor GC之前，虚拟机会检查老年代可用连续空间是否大于新生代对象总空间，若成立则Minor GC是安全的，否则需要查看是否允许担保失败，若允许则检查历次从新生代晋升到老年代的对象平均大小，若小于则进行Minor GC（虽然有风险），若不允许冒险或大于则进行一次 Full GC。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux]]></title>
    <url>%2F2016%2F11%2F10%2Flinux%2F</url>
    <content type="text"><![CDATA[Linux常用命令显示日期：date +%Y%m%d date +%H：%M显示日历al cal 年月日：cal month year计算器：bc quit退出帮助指令：man man 命令数据同步磁盘：sync关机：shutdown -t（秒）-r（重启） -h（停止系统服务后关机）重启：reboot 改变群组： chgrp -r（递归） 文件／目录改变拥有者：chown -r 拥有者：群组 文件／目录改变属性：chmod -r 数字 文件／目录 （rwx：421） 目录所在磁盘信息：df -a（所有）-k（kb） -m（mb）-h（gb，mb，kb自行显示） 文件／目录当前目录所有文件容量：du -a(所有) -s（总量）-k（kb）目录连接档：in hard link（硬连接、实际连接，指向同一档案、不占空间、删除原始档不受影响） symbolic link（符号连接、快捷方式、占空间、删除原始档后不可用） 用法 ：in -s（符号连接、默认硬连接） -f（若存在同名删除再建立） 源文件 目标文件 磁盘分割：fdisk -l(所有装置) 装置名称 进入后会有一些命令，主要有： l 显示所有硬盘信息； n新增一个磁盘分区； p显示磁盘分区 d删除一个磁盘分区 q不存储离开 w写入磁盘分区表离开格式化磁盘：mke2fs -b（设置bolck大小）-c（检查错误）磁盘名称磁盘检验：fsck -A（所有装置扫描）-a（自动修复） -f（强制进行细部检查）磁盘挂载：mount -a(所有磁盘全部挂载) -t（指定格式类型） 装置名称 挂载点卸载装置：umount 装置代号／挂载点 虚拟内存： 将目录格式化为swap档案格式：mkswap 目录 启动：swapon 目录 关闭：swapoff 目录 删除空的目录：rmdir -p（递归删除）目录复制文档目录：cp -l（hard link建立）-p（连属性一起复制过去）-r（递归）-s（symbolic link） -u（更新目标文件） 源文件 目标文件删除档案目录：rm -f（强制） -r（递归） 文件／目录移动档案／目录：mv -f（强制） -u（更新） 源 目的 查看：cat -n（行号） -A（显示特殊字符） 文件 一页一页翻动 ：more 文件 空格键：向下翻一页 enter：下一行 ／字符串：搜索字符串 :f ：显示文件名和行数 q：退出 less 文件 空格键：向下翻一页 pagedown：向下一页 pageup：向上一页 ／字符串：向下搜索字符串 ？／：向上搜索字符串 q：退出取出前面几行：head -n（n行） 文件后面几行：tail -n 文件非ascll文件（二进制）：od -t （类型） 文件touch -a（修改atime）-c（修改ctime）-m（修改mtime）文件 预设权限：umask 数字设置隐藏属性：chattr +-= 文件 常见的：i：无法修改、增加 、删除 a：只能增加不能修改删除查看隐藏属性：lsattr -a(隐藏属性) -R（递归子目录） 文件文件类型：file 文件文件查找： 查找执行档(命令)：which -a（所有同名） 文件名 查找特定档案（二进制、源文件、man说明文件）：whereis -b（二进制文件）-s（source来源） -m（manual路径下） 文件 locate 文件名（可以查找部分匹配文件名的文件） 文件名 find 路径 参数 （-name filename） （-user username） （-group name） 压缩打包： gzip -d（解压缩） 文件 zcat：查看gzip压缩文件内容 bzip2 -z(压缩) -d(解压缩) 文件 bzcat ：查看bzip2压缩的文件 tar -c(建立) -x(解开) -t(查看) -v（压缩过程显示文件）-f(使用档名) -z(使用gzip) -j(使用bzip2 ) -P（使用绝对路径）-p（保持原来文件属性） eg：tar -zcvf /tmp/a.tar.gz /home /etc 把home 和 etc目录打包并gzip压缩到／tmp下的a中 tar -zxvf ／tmp／a.tar.gz ／home 将 文件中的home先gzip解压然后解开打包 最后放在当前目录下 dd if= of= (bs= 默认512 count=) 截取命令： cut： -d 分割字符（单个字符）与 -f一起使用 -f 取出第几段 与-d配合使用 -c 取出固定的字符区间 eg：echo ￥path | cut -d ‘：’ -f 5 取出path种以：分割的第5块 export | cut -c 12- 取出export配置第12个开始后的所有字符 grep: -c:计算匹配次数 -n：显示行号 -v:反过来没有匹配的那一行 -i：忽略大小写]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Commands</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Classbytes]]></title>
    <url>%2F2016%2F09%2F04%2Fclassbytes%2F</url>
    <content type="text"><![CDATA[JVM字节码执行引擎和编译、优化java作为跨平台的语言离不开jvm的支持，java语言首先经过javac编译器编译为class字节码文件然后被jvm解释、编译为本地机器码，然后被os执行，由于jvm中间这一层的存在所以java语言才能跨平台，同时除了java，ruby、scala等语言经过编译后的字节码只要符合jvm字节码规范也能够被jvm执行，所以字节码是一种规范，了解jvm执行引擎对学习java也很有帮助。一、字节码执行引擎1.1运行时栈帧结构栈帧是支持jvm方法调用、执行的数据结构，是jvm运行时虚拟机栈的栈元素。栈帧存储了方法的局部变量表、操作数栈、动态链接、方法返回地址，每一个方法调用到结束对应了一个栈帧在虚拟机栈中从入栈到出栈的过程。局部变量表存放了方法参数和局部变量，以slot（变量槽）为最小单位，操作数栈是一个后入先出的栈（LIFO），32位，方法返回值用于方法执行完将返回值返回上层方法调用，对于异常抛出未处理时是没有返回值（异常表处理），修改PC计数器。 1.2方法调用方法调用确定被调用方法的版本（具体来说是调用哪一个方法），class文件的编译不包括链接步骤，方法调用在class文件中是符号引用，需要转化为直接引用（入口地址）。 解析调用：在类加载阶段把符号引用转化为直接引用，在方法运行前有可确定的调用版本并且在运行时不可变，也就是说在编译时确定了方法的调用。java中方法调用的直接码指令有：1.invokestatic 静态方法2.invokespecial 实例构造器、私有方法、父类方法3.invokeinterface方法接口，运行时确定是实现接口的对象4.invokedynamic5.invokevirtual虚方法其中invoke static、invoke special都可以在解析阶段确定，invoke virtual中带有final的方法。解析调用是静态过程，在编译期确定了，不会到运行期再去完成。 分派：分派调用可能是静态的也可能是动态的。 静态分派：重载，java中变量有静态类型（外观类型）、实际类型。静态类型在编译期已知，实际类型在运行期才可以确定，所以重载是属于静态分派，在编译期已经确定了，并不是由jvm来确定，重载时也会选择最佳的匹配方法。 动态分派：重写，根据对象实际类型选择方法调用。动态分派过程如下：1.找到对象实际类型C2.在类型C中找到与常量描述都相同的方法，进行访问权限校验，通过返回直接引用否则返回java.lang.IllegalAccessError3.否则，按照继承关系对父类进行第二步的搜索验证4.没有找到合适方法，抛出java.lang;AbstractMethodError其中，静态分派调用是一方面会判断对象的静态类型也会判断方法的参数，所以它属于静态多分派；动态分派只会根据实际类型判断，所以属于动态多分派。动态分派在实现时，jvm在方法区存放了一个虚方法表，同样invokeinterface存在一个接口方法表，虚方法表中存放了方法的实际入口地址，若子类未复写则子类和父类地址一致，指向父类入口，若复写了则指向子类实现的入口地址，方法表在类加载阶段连接是进行，初始化类变量后对方法表也进行了初始化。 二、编译、优化java语言的编译阶段主要有2种，包括了前端编译期（java－&gt;class）、运行期编译期（JIT编译器，字节码－&gt;机器码）。 2.1早期编译java编译器本身由java语言编写，它对代码的运行效率几乎没有任何优化措施，性能优化主要集中在JIT中。javac编译器的编译过程主要有3个过程： 1.解析和填充符号表过程 词法分析、语法分析；填充符号表 2.插入式注解处理器的注解处理过程 注解支持 3.分析和字节码生产过程 语义分析（标注检查、数据流、控制流分析）；解语法糖（泛型、自动装箱）；字节码生成 2.2晚期优化 混合编译模式：java程序最初通过解释器进行解释执行，当jvm发现某个代码运行频繁时，将把这些代码认为“热点代码”，在运行时把这些代码编译成本地机器码进行各种层次优化，这些都由JIT编译器完成，下面以hotspot为例介绍运行期的优化方法。主流的JVM都同时包含了解释器和编译器。解释器省去编译时间可以迅速启动，在程序运行中编译器可以把代码编译成本地代码提高执行效率，而且当编译器激进优化不成立时能够通过逆优化退回到解释执行。HotSpot中设置了2个即时编译器，分别为client、server，server优化程度更深更复杂。 编译优化触发条件：被编译优化的“热点代码”主要有2类：多次调用的方法、多次执行的循环体。第一种编译器以整个方法作为编译对象，后一种编译由循环体触发，但JIT还是会以整个方法（而不是循环体）作为编译对象，这种方式发生在方法执行过程中，成为栈上替换（on stack replacement）OSR，方法在栈上，方法被替换了。 热点代码的判定方法主要有2种：采样热点探测、计数器探测 1.基于采样热点探测：jvm周期性检查线程栈顶，某个方法经常出现则为热点代码，并能发现方法的调用关系，但容易受外界干扰（线程阻塞） 2.基于计数器热点探测：建立计数器，统计方法执行次数，超过阈值即为热点代码，但不能发现方法调用关系 hotspot以第二种方法判断热点代码，计数器有方法计数器和回边计数器，方法调用计数器、回边计数器运行过程分别如下： 如果不做设置，方法调用计数器统计的不是绝对次数，而是相对次数，在一定时间的调用次数，超过一定时间会减半即热衰减，也可以设置来关闭热衰减。回边计数器，统计了方法中循环体的次数，回边计数器没有热衰退。在方法调用发出即使编译请求后，在代码编译未完成前仍然按解释方式执行，编译过程在后台编译线程中执行，也可以设置关闭后台编译，等待编译完成在执行编译后本地代码。 编译方式比解释方式执行速度快，一方面是执行本地代码快，另一方面JIT编译时进行了优化，主要的优化有： 1.公共子表达式消除 2.数组范围检查消除 3.方法内联 4.逃逸分析]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Classloader]]></title>
    <url>%2F2016%2F09%2F04%2Fclassloader%2F</url>
    <content type="text"><![CDATA[JVM类加载机制类从被加载到虚拟机内存中开始到卸载出内存，整个的生命周期包括：加载、验证、准备、解析、初始化、使用、卸载，其中验证、准备、解析阶段统成为连接，7阶段关系如下图：其中，加载、验证、准备、初始化、卸载顺序是确定的，而解析阶段不一样，可以在初始化之后再开始，这是为了支持java的运行时绑定。这些阶段通常都是互相交叉混合进行，在一个阶段执行过程中调用激活另一个阶段。 1.类加载时机 java虚拟机规范没有约束加载阶段，由具体的虚拟机实现来把握，而初始化阶段却有严格的规定，以下五种情况必须对类进行初始化： （1）使用new、getstatic、putstatic、invokestatic字节码指令时，类没有初始化，必须对类进行初始化 （2）使用reflect对类进行反射调用 （3）初始化类时，父类未初始化则需要触发类初始化 （4）jvm启动，会初始化指定包含main方法那个类 （5）jdk1.7动态语言支持，java.lang.invoke.methodhandle实例后的解析结果REF_getStatiic、REF_putStatiic、REF_invokeStatiic的方法句柄，这个方法句柄对应类没有初始化，首先要初始化该类 对于这5种初始化场景成为类主动引用，除此之外其他的方式成为被动引用，不会触发初始化，常见的被动引用有： （1）子类使用父类中static字段 （2）new对象数组 （3）使用类的final static字段 2.加载过程 加载阶段jvm完成以下3件事情： （1）通过类的全限定名来获取类的二进制字节流 （2）将字节流代表的静态存储结构转化为方法区运行时数据结构 （3）在内存中（方法区）生产代表这个类的class对象 其中第一条并没有指定必须从class文件获取，其实有很多技术建立在这一基础上： （1）从zip包获取：jar、war、ear格式基础 （2）网络获取，applet （3）运行时生产，动态代理技术，proxy，cglib （4）数据库或其他文件获取 3.验证 验证阶段保证了class文件的字节流信息符合jvm要求，不会危害jvm安全，主要包含了： （1）文件格式验证 （2）元数据验证 （3）字节码验证 （4）符号应用验证 具体验证内容需要对类文件结构有一定理解。 4.准备 准备阶段为类变量分配内存设置变量初始值，这里分配的是static变量，而非实例对象，并将static变量初始化为“零值”，而final static变量在准备阶段以及赋值为指定的值。 5.解析 解析阶段将常量池中符号引用替换为直接引用，主要包含：（1）类、接口解析（2）字段解析（3）类方法解析（4）接口方法解析 6.初始化 初始化是类加载最后一步，该阶段开始执行用户java代码，在准备阶段对类变量赋值为零值，而初始化将对类变量赋初始值。从另一个角度来说初始化阶段是执行类构造器方法过程，收集类变量赋值和static块（有先后顺序），有以下几点需要注意：（1）jvm保证子类clinit执行前，父类clinit已经执行完毕（2）clinit对于类并非必须，没有类变量和static也就不需要了（3）接口不能使用static块，但有变量初始化过程，与类不同之处在于接口clinit方法不需要执行父接口clinit方法，除非使用了父接口的变量（4）jvm会保证clinit方法的同步、加锁，只执行一次 7.类加载器 java中任何一个类，都需要一个类加载器来进行加载，比较2个类是否相等，需要保证其来自的class文件相同并且被同一类加载器加载，否则是2个不同的类。java中类加载机制称为双亲委派模型，如下图所示：(1).BootStrap ClassLoader：启动类加载器，负责加载存放在%JAVA_HOME%\lib目录中的，或者通被-Xbootclasspath参数所指定的路径中的，并且被java虚拟机识别的(仅按照文件名识别，如rt.jar，名字不符合的类库，即使放在指定路径中也不会被加载)类库到虚拟机的内存中，启动类加载器无法被java程序直接引用。(2).Extension ClassLoader：扩展类加载器，由sun.misc.Launcher$ExtClassLoader实现，负责加载%JAVA_HOME%\lib\ext目录中的，或者被java.ext.dirs系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器。(3).Application ClassLoader：应用程序类加载器，由sun.misc.Launcher$AppClassLoader实现，负责加载用户类路径classpath上所指定的类库，是类加载器ClassLoader中的getSystemClassLoader()方法的返回值，开发者可以直接使用应用程序类加载器，如果程序中没有自定义过类加载器，该加载器就是程序中默认的类加载器。 上述三个JDK提供的类加载器虽然是父子类加载器关系，但是没有使用继承，而是使用了组合关系，加载顺序如下： (1).如果一个类加载器收到了类加载请求，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器去完成。(2).每一层的类加载器都把类加载请求委派给父类加载器，直到所有的类加载请求都应该传递给顶层的启动类加载器。(3).如果顶层的启动类加载器无法完成加载请求，子类加载器尝试去加载，如果连最初发起类加载请求的类加载器也无法完成加载请求时，将会抛出ClassNotFoundException，而不再调用其子类加载器去进行类加载。 在JDK1.2之前，自定义类加载器都要覆盖loadClass方法去实现加载类的功能，JDK1.2引入双亲委派模型之后，loadClass方法用于委派父类加载器进行类加载，只有父类加载器无法完成类加载请求时才调用自己的findClass方法进行类加载，因此在JDK1.2之前的类加载的loadClass方法没有遵循双亲委派模型，因此在JDK1.2之后，自定义类加载器不推荐覆盖loadClass方法，而只需要覆盖findClass方法即可。双亲委派 模式的类加载机制的优点是java类它的类加载器一起具备了一种带优先级的层次关系，越是基础的类，越是被上层的类加载器进行加载，保证了java程序的稳定运行。 8.tomcat案例分析tomcat web服务器解决的问题：（1）不同web应用使用了同一个第三方类库的不同版本，需要包装不同webapp类库可以相互独立（2）同一web服务器上的webapp使用的java类库相互共享，如spring，如果将所有类库都进行加载，加载的类太多，方法区可能会溢出，所以需要解决共享问题（3）web服务 器需要保证自身安全，自身类库和webapp类库隔离（4）某一个webapp的jsp应用tomcat采用了不同的类加载器来解决这些问题，它有／common、／server、／shared目录，web应用的类库在自己目录／WEB_INF下,一共有4类目录，tomcat在处理时采用了如下方式：（1）／common：被tomcat和所有webapp共享（2）／server：只能被tomcat使用（3）／shared：只能被所有webapp使用（4）／webapp／web－info：仅对某一webapp使用类加载器如下：tomcat遵循了双亲委派机制，而OSGI作为一种灵活的类加载架构，对类加载有更大的启发，以后有时间多学习学习。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven]]></title>
    <url>%2F2016%2F07%2F22%2Fmaven%2F</url>
    <content type="text"><![CDATA[Maven简介Maven 是一个项目管理和构建自动化工具，它包含了一个项目对象模型，一组标准集合，一个项目生命周期，一个依赖管理系统，和用来运行定义在生命周期阶段中插件目标的逻辑。使用maven创建项目后，文件目录如下： 目录 目的 ${basedir} 存放 pom.xml和所有的子目录 ${basedir}/src/main/java 项目的 java源代码 ${basedir}/src/main/resources 项目的资源，比如说 property文件 ${basedir}/src/test/java 项目的测试类，比如说 JUnit代码 ${basedir}/src/test/resources 测试使用的资源 maven中重要的一个文件是pom文件，上面是一个简单的pom文件：其中groupId, artifactId, packaging, version 叫作 maven 坐标，它能唯一的确定一个项目。有了 maven 坐标，我们就可以用它来指定我们的项目所依赖的其他项目，插件，或者父项目。在复杂的项目中，大项目一般会分成几个子项目。在这种情况下，每个子项目就会有自己的 POM 文件，然后它们会有一个共同的父项目。这样只要构建父项目就能够构建所有的子项目了，子项目的 POM 会继承父项目的 POM。 下面我们从maven库，生命周期，依赖库来对maven进行介绍： 1.maven库 maven库分本地库、中央存储库、远程存储库。其中，本地库指 maven 下载了插件或者 jar 文件后存放在本地机器上的拷贝。在 Linux，mac os 上，它的位置在 ~/.m2/repository，在 Windows XP 上，在 C:\Documents and Settings\username.m2\repository ，在 Windows 上，在 C:\Users\username.m2\repository，我们可以修改setting.xml中localRepository结点来改变本地库的位置。当你建立一个 Maven 的项目，Maven 会检查你的 pom.xml 文件，以确定哪些依赖下载。首先，Maven 将从本地资源库获得 Maven 的本地资源库依赖资源，如果没有找到，然后把它会从默认的 Maven 中央存储库 – http://repo1.maven.org/maven2/ 查找下载。在Maven中，当你声明的库不存在于本地存储库中，也没有不存在于Maven中心储存库，可以设置从远程存储库中搜索，设置的方式如下，会从java.net中搜索需要的jar： 所以Maven的依赖库查询顺序为： 在 Maven 本地资源库中搜索，如果没有找到，进入第 2 步，否则退出。 在 Maven 中央存储库搜索，如果没有找到，进入第 3 步，否则退出。 在java.net Maven的远程存储库搜索，如果没有找到，提示错误信息，否则退出。 2.Maven 生命周期 Maven的生命周期就是对所有的构建过程进行抽象和统一。包含了项目的清理、初始化、编译、测试、打包、集成测试、验证、部署和站点生成等几乎所有的构建步骤。Maven有三套相互独立的生命周期，分别是clean、default和site。每个生命周期包含一些阶段（phase），阶段是有顺序的，后面的阶段依赖于前面。 clean生命周期：清理项目，包含三个phase。 1）pre-clean：执行清理前需要完成的工作 2）clean：清理上一次构建生成的文件 3）post-clean：执行清理后需要完成的工作 default（build）生命周期：构建项目，重要的phase如下。 1）validate：验证工程是否正确，所有需要的资源是否可用。 2）compile：编译项目的源代码。 3）test：使用合适的单元测试框架来测试已编译的源代码。这些测试不需要已打包和布署。 4）Package：把已编译的代码打包成可发布的格式，比如jar。 5）integration-test：如有需要，将包处理和发布到一个能够进行集成测试的环境。 6）verify：运行所有检查，验证包是否有效且达到质量标准。 7）install：把包安装到maven本地仓库，可以被其他工程作为依赖来使用。 8）Deploy：在集成或者发布环境下执行，将最终版本的包拷贝到远程的repository，使得其他的开发者或者工程可以共享。 site生命周期：建立和发布项目站点，phase如下 1）pre-site：生成项目站点之前需要完成的工作 2）site：生成项目站点文档 3）post-site：生成项目站点之后需要完成的工作 4）site-deploy：将项目站点发布到服务器 各个生命周期相互独立，一个生命周期的阶段前后依赖，如mvn clean install，调用clean生命周期的clean阶段和default的install阶段，实际执行pre-clean和clean，install以及之前所有阶段。maven插件目标可以绑定到生命周期阶段上。一个生命周期阶段可以绑定多个插件目标。当 maven 在构建过程中逐步的通过每个阶段时，会执行该阶段所有的插件目标。 3.Maven依赖管理 赖是使用Maven坐标来定位的，而Maven坐标主要groupId, artifactId, version构成，随着项目的增大，依赖越来越多，兼容性和冲突问题将会出现，maven通过依赖范围和传递性依赖以及排除依赖来管理依赖问题。下面是一个简单的依赖配置文件：12345678&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; maven不但下载了 junit-3.8.1.jar，还下载了它的 POM 文件。这样 maven 就能检查 junit 的依赖关系，把它所需要的依赖也包括进来。依赖的主要几个元素如下： groupId,artifactId和version：依赖的基本坐标，对于任何一个依赖来说，基本坐标是最重要的，Maven根据坐标才能找到需要的依赖type: 依赖的类型，对应于项目坐标定义的packaging。大部分情况下，该元素不必声明，其默认值是jarscope: 依赖的范围optional: 标记依赖是否可选exclusions: 用来排除传递性依赖scope指依赖范围，主要有compile、test、provided、runtime、system这几类，是用来控制依赖与这三种classpath(编译classpath、测试classpath、运行classpath)的关系，它们的范围如下：compile: 编译依赖范围。如果没有指定，就会默认使用该依赖范围。使用此依赖范围的Maven依赖，对于编译、测试、运行test: 测试依赖范围。使用此依赖范围的Maven依赖，只对于测试classpath有效provided: 已提供依赖范围。使用此依赖范围的Maven依赖，对于编译和测试classpath有效，但在运行时无效。典型的例子是servlet-api，编译和测试项目的时候需要该依赖，但在运行项目的时候，由于容器已经提供，就不需要Maven重复地引入一遍。runtime: 运行时依赖范围。使用此依赖范围的Maven依赖，对于测试和运行classpath有效，但在编译主代码时无效。典型的例子是JDBC驱动实现，项目主代码的编译只需要JDK提供的JDBC接口，只有在执行测试或者运行项目的时候才需要实现上述接口的具体JDBC驱动。system: 系统依赖范围。该依赖与三种classpath的关系，和provided依赖范围完全一致。但是，使用system范围依赖时必须通过systemPath元素显式地指定依赖文件的路径。 当我们引入第三方jar包的时候，难免会引入传递性依赖，有些时候这是好事，然而有些时候我们不需要其中的一些传递性依赖，可以在们可以使用exclusions元素声明排除依赖，exclusions可以包含一个或者多个exclusion子元素，因此可以排除一个或者多个传递性依赖。需要注意的是，声明exclusions的时候只需要groupId和artifactId，而不需要version元素，这是因为只需要groupId和artifactId就能唯一定位依赖图中的某个依赖，不会出现重复。 当同一个模块，所依赖的几个模块版本都相同时，可以使用maven里的属性做分类依赖，依赖版本升级时改一处即可，如Spring Framework的依赖，可以使用 如下方式： 123&lt;properties&gt; &lt;springframework.version&gt;2.5.6&lt;/springframework.version&gt;&lt;/properties&gt; 然后在dependency中使用这个版本即可。]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Concurrenthashmap]]></title>
    <url>%2F2016%2F07%2F19%2Fconcurrenthashmap%2F</url>
    <content type="text"><![CDATA[ConcurrentHashmap 大家都知道java集合框架中，hashmap是非线程安全的，在并发环境下会出现错误情况，具体的原因分析参考：hashmap线程安全性。java也提供了相应的线程安全类，如hashtable、ConcurrentHashMap等。下面介绍一下ConcurrentHashmap。首先hashtable也是线程安全的，通过分析源码发现hashtable是通过synchronized同步了整个hash表，只允许一个线程对hashtable进行读写，所以并发时造成多个线程等待效率较低。而ConcurrentHashMap允许多个线程并发操作，其关键在于使用了锁分离技术，它使用了多个锁来控制对hash表的不同部分进行的修改。ConcurrentHashMap内部使用段(Segment)来表示这些不同的部分，每个段其实就是一个小的hashtable，它们有自己的锁。只要多个修改操作发生在不同的段上，它们就可以并发进行。对于有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁。 ConcurrentHashmap的结构如下： 由上图可以看出，ConcurrentHashmap是整个hash表，它由多个（默认16个）segment组成，相当于一个hashtable，hashentry是链表一个节点。下面看一下主要的源代码：12345public class ConcurrentHashMap&lt;K, V&gt; extends AbstractMap&lt;K, V&gt; implements ConcurrentMap&lt;K, V&gt;, Serializable &#123; final int segmentMask; final int segmentShift; final Segment&lt;K,V&gt;[] segments;&#125; 这表明ConcurrentHashmap的segment是不可变的，扩容只能增加segment的大小，其数量不会发生变化。segment的源码如下：12345678static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; transient volatile int count; transient int modCount; transient int threshold; transient volatile HashEntry&lt;K,V&gt;[] table; final float loadFactor;&#125; HashEntry是volatile，则其修改对于其他线程是可见的，hashentry源码如下：123456static final class HashEntry&lt;K,V&gt;&#123; final K key; final int hash; volatile V value; final HashEntry&lt;K,V&gt; next;&#125; 除了value不是final的，其它值都是final的，所以不能从hash链的中间或尾部添加或删除节点，为了确保读操作能够看到最新的值，将value设置成volatile，这避免了加锁。ConcurrentHashmap这种设计，保证读取操作能够读取到几乎最新的修改，所以读操作大多数情况了不需要加锁。 下面看一下remove操作：12345public V remove(Object key) &#123; hash = hash(key.hashCode()); return segmentFor(hash).remove(key, hash, null);&#125; 整个操作是先定位到段，然后委托给段的remove操作。当多个删除操作并发进行时，只要它们所在的段不相同，它们就可以同时进行。下面是Segment的remove方法实现： 整个操作是在持有segment锁的情况下执行的，先定为代需要删除的节点e，然后将e前面的节点都复制一遍，因为entry是不可变的，所以必须要复制前面的节点，这种不可变性使得不需要同步从而节省了时间。例如删除前的数据为：1、2、3、4，删除3后链表变为：2、1、4。 整个remove实现并不复杂，但是需要注意如下几点。第一，当要删除的结点存在时，删除的最后一步操作要将count的值减一。这必须是最后一步操作，否则读取操作可能看不到之前对段所做的结构性修改。第二，remove执行的开始就将table赋给一个局部变量tab，这是因为table是 volatile变量，读写volatile变量的开销很大。编译器也不能对volatile变量的读写做任何优化，直接多次访问非volatile实例变量没有多大影响，编译器会做相应优化。 接下来看一下put操作：修改数据是不能并发进行的，所以该方法也是在持有segment锁的情况下执行，然后判断是否超限确保容量不足时能够rehash。接着是找是否存在同样一个key的结点，如果存在就直接替换这个结点的值。否则创建一个新的结点并添加到hash链的头部，这时一定要修改modCount和count的值，同样修改count的值一定要放在最后一步。put方法调用了rehash方法，reash方法实现得也很精巧，主要利用了table的大小为2^n。 然后看一下get操作： get操作不需要锁。第一步是访问count变量，这是一个volatile变量，由于所有的修改操作在进行结构修改时都会在最后一步写count 变量，通过这种机制保证get操作能够得到几乎最新的结构更新。对于非结构更新，也就是结点值的改变，由于HashEntry的value变量是 volatile的，也能保证读取到最新的值。接下来就是根据hash和key对hash链进行遍历找到要获取的结点，对hash链进行遍历不需要加锁的原因在于链指针next是final的。但是头指针却不是final的，这是通过getFirst(hash)方法返回，也就是存在 table数组中的值。这使得getFirst(hash)可能返回过时的头结点，例如，当执行get方法时，刚执行完getFirst(hash)之后，另一个线程执行了删除操作并更新头结点，这就导致get方法中返回的头结点不是最新的。这是可以允许，通过对count变量的协调机制，get能读取到几乎最新的数据，虽然可能不是最新的。要得到最新的数据，只有采用完全的同步。最后，如果找到了所求的结点，判断它的值如果非空就直接返回，否则在有锁的状态下再读一次。因为put操作的语句：tab[index] = new HashEntry(key, hash, first, value)，在这条语句中，HashEntry构造函数中对value的赋值以及对tab[index]的赋值可能被重新排序，这就可能导致结点的值为空，所以可能需要在加锁情况在在读一遍： contains方法更简单了，他不需要读值，所以不需要加锁了。最后看一下size（）操作： size方法主要思路是先在没有锁的情况下对所有段大小求和，如果不能成功（这是因为遍历过程中可能有其它线程正在对已经遍历过的段进行结构性更新），最多执行RETRIES_BEFORE_LOCK次，如果还不成功就在持有所有段锁的情况下再对所有段大小求和。在没有锁的情况下主要是利用Segment中的modCount进行检测，在遍历过程中保存每个Segment的modCount，遍历完成之后再检测每个Segment的modCount有没有改变，如果有改变表示有其它线程正在对Segment进行结构性并发更新，需要重新计算。 ConcurrentHashmap主要的方法大概这么多，其同步的方法在于使用了分段锁、final、volatile等减少了同步的范围，并保证了可见行。它的实现也比较复杂，需要多多思考和理解。]]></content>
      <categories>
        <category>Concurrent</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>DataStructure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Violate]]></title>
    <url>%2F2016%2F07%2F18%2Fviolate%2F</url>
    <content type="text"><![CDATA[Java violate关键字分析在java高并发环境下，多个线程之间可能存在资源共享情况，可能造成了数据不一致情况。很多人都想到可以利用加锁的方式来实现，如java中的synchronized同步块和Lock，然而这种方式虽然可以解决问题，但加锁的本质是thread，只允许同一时刻只有一个线程来访问同步块，而在有些情况下我们并不需要严格的同步，只保证能读写最新的值即可，所以volatile能达到这个效果。在学习java并发编程前，我们先简单了解一下java内存模型。 1.JMMJava内存模型中规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程使用到的变量到主内存副本拷贝，线程对变量的所有操作（读取、赋值）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程之间无法直接访问对方工作内存中的变量，线程间变量值的传递均需要在主内存来完成，线程、主内存和工作内存的交互关系如下图所示： read and load 从主存复制变量到当前工作内存use and assign 执行代码，改变共享变量值store and write 用工作内存数据刷新主存相关内容 如：x＝1这条语句 执行线程必须先在自己的工作线程中对变量x所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值1写入主存中。下面继续分析并发编程中原子性、可见行、顺序性等概念。 2.原子性在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，这些操作是不可被中断的，要么执行，要么不执行，这和数据库中事物的原子性概念很类似。 如 x = 10; y = x; x＋＋；x＝x＋1在上面4个语句中，只有第一个是原子操作，其他都是复合操作，语句2包含2个操作，它先要去读取x的值，再将x的值写入工作内存，语句3和4都包含3个操作：读取x的值，进行加1操作，写入新的值 。所以只有简单的读取、赋值（变量之间的相互赋值不是原子操作）才是原子操作，另外在32位机器上，long等64位数据赋值也不是原子操作。 3.可见性可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。Java提供了volatile关键字来保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 4.有序性有序性：即程序执行的顺序按照代码的先后顺序执行，如下例子所示： int i = 0;boolean flag = false;i = 1; //1flag = true; //2 上面例子中，语句1和2之间没有任何关系，jvm不能保证1一定在2前面执行，因为有可能发生指令重排序。指令重排序是指处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。下面是另一个例子： int a = 10;int r = 2;a = a + 3; //1r = a*a; //2 这种情况下语句2不会在语句1前面执行，因为r的计算依赖语句1的操作结果。所以有序性只保证程序最终执行结果和代码顺序执行的结果是一致的，并没有强调执行语句必须与程序代码一致，这样在单个线程中不会出现任何问题，然而在多个线程下会存在问题，上面例子中语句1，2在不同线程中，则r的值有可能不正确。要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。 java中volatile关键字来保证了一定的“有序性”，同样synchronized和Lock也可以保证有序性。另外jvm内存模型中具备了一些先天的有序性：happens-before 原则，具体规则如下： 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作 volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始 5.volatile剖析在简单理解了jmm后，我们先在分析一下volatile关键字的作用。volatile实际上有2个作用：1).保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。2).禁止进行指令重排序(内存屏障），它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面 下面结合一些经典的例子讲解一下：在java中，thread的stop方法是极不推荐的，为了停止线程通常的做法设置一个标记： //线程1boolean stop = false;while(!stop){ doSomething();}//线程2stop = true; 线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。用volatile修饰之后会强制将修改的值立即写入主存，导致线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取，所以stop的值就是最新的值，线程就停止了。 下面是另一个典型的例子：1234567891011121314151617181920212223public class Test &#123; public volatile int inc = 0; public void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) Thread.yield(); System.out.println(test.inc); &#125;&#125; 上面的操作大多数情况下都不是1000，因为volatile并不能保证原子性。上述例子中关键在于inc＋＋这个复合操作，分为读取、增加、写入三部操作，假设线程1从主存中读取了值，然后将值加一但还未写入主存，此时线程2也从内存中读取了值（此时和线程1读取的值一样，因为线程1还没将结果写入）然后增加写入，此时线程1继续执行，它已经不需要读取inc的值了，直接把计算的结果写入，所以这个时候线程2的增加操作被覆盖，导致只增加一次。使用synchronized和lock可以保证执行结果的正确性，也可以使用concurrent包下面的AtomicInteger类等。 volatile不能保证操作的原子性，但可以保证有序性。在单例模式中，通常通过double－check来提升单例的执行效率：12345678910111213141516class Singleton&#123; private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance==null) &#123; synchronized (Singleton.class) &#123; if(instance==null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 这里使用volatile关键在于instance = new Singleton()这条语句本质包括了3个步骤：1:在堆中分配内存 2： 初始化堆中的对象 3:将堆中对象引用复制给instance然后，上述三步中2和3是有可能发生指令重排序的，若先执行了3，此时instance非null，但堆中对象未初始化不能使用，若另一线程刚好执行到getInstance（）第一行，在判断 if(instance==null) 时程序会出现异常，所以volatile内存屏障防止了指令重排序，保证了2先于3发生。 总结：volatile在某些情况下能保证并发的执行效率，但它并不能保证原子性，所以使用volatile时synchronized和lock一定能达到同样的效果，但反过来就不能保证。理解java中并发编程需要对jvm和操作系统有一定的了解，还需要多多学习。]]></content>
      <categories>
        <category>Concurrent</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dispatchservlet]]></title>
    <url>%2F2016%2F07%2F16%2Fdispatchservlet%2F</url>
    <content type="text"><![CDATA[SpringMVC框架概括SpringMVC是web开发中一种优良的MVC框架，它分离了控制器、模型对象、分派器以及处理程序对象的角色。当前的MVC框架有多种，主要有Struts1.x、Struts2、SpringMVC，而这些MVC框架都是在围绕着Controller进行重构和改善，他们主要的特点可以简单的概括为下图。 Struts1.x是一个早期的MVC框架实现，它保留了servlet中HttpServletRequest和HttpServletResponse这两大接口作为参数，另外它将返回值改为ActionForward完成对响应结果的处理，除此之外它增加了ActionMapping和ActionForm两大参数，相比传统的servlet，它优化了逻辑处理过程。struts2主要有2个创新点，首先消除了HttpServletRequest或者HttpServletResponse这样的原生Servlet对象，其次将请求参数和响应数据从响应方法中剥离到controller对象中的属性。这样整个Controller类彻底与Web容器解耦，摆脱了servlet的束缚，最后servlet引入了ThreadLocal模式，使得Controller成为一个线程安全的对象被servlet模型使用，它的拦截器、OGNL等技术使它成为一个流行的MVC框架。 SpringMVC的创新之处在于它引入Annotation来完成请求-响应的映射关系 ，在JDK1.5普及之后，Annotation作为一种新兴的Java语法，逐渐被大家熟知和应用。另外SpringMVC在响应方法上，可以支持多种多样不同的参数类型和返回值类型，当参数类型为Model时，SpringMVC将会自动将请求参数封装于Model内部而传入请求方法；当返回值类型是String时，直接表示SpringMVC需要返回的视图类型和视图内容，在写Controller的代码时可以随心所欲，不再受到任何契约的束缚。 SpringMVC的主要工作流程如下图所示： 用户向服务器发送请求，请求被Spring 前端控制Servelt DispatcherServlet捕获； DispatcherServlet对请求URL进行解析，得到请求资源标识符（URI）。然后根据该URI，调用HandlerMapping获得该Handler配置的所有相关的对象（包括Handler对象以及Handler对象对应的拦截器），最后以HandlerExecutionChain对象的形式返回； DispatcherServlet 根据获得的Handler，选择一个合适的HandlerAdapter，如果成功获得HandlerAdapter后，此时将开始执行拦截器的方法，拦截器的作用是拦截用户请求并在执行controller中方法之前或之后进行相应的处理，主要有3个方法，boolean preHandle在处理请求之前被调用，当一 个请求中存在多个拦截器时，拦截器会根据其声明顺序依次执行其preHandle 方法，返回为false 时则请求结束，后续拦截器和对应Handler都不会再被调用，当返回值为true 时就会继续调用下一个拦截器的preHandle方法。 void postHandle是处理请求之后DispatcherServlet 对视图进行渲染之 前被调用。postHandle方法被调用的顺序与拦截器声明的顺序相反。 void afterCompletion在DispatcherServlet 渲染视图之后被调用，当对应的拦截器的preHandle方法的返回值为true时才会执行，主要用于进行资源清理工作。4.DispatcherServlet调用ViewResolver，ViewResolver根据ModelAndView对象中的信息解析得到对应的View对象（使用了freemarker的视图解析器）；5.DispatcherServlet调用View，View根据ModelAndView对象中Model中的数据进行页面渲染；6.DispatcherServlet返回响应给用户。 在项目使用Spring MVC首先需要在web.xml配置对应的servlet，servlet-mapping配置指定了由Spring MVC 处理的请求的路径。在web.xml中也可以通过配置context-param来指定spring配置文件的路径，可以指定多个配置文件的路径。 在spring的配置文件中配置ViewResolver，HandlerMapping和HandlerAdapter，项目中可以使用freemarker实现视图， 配置会在spring容器中注册DefaultAnnotationHandlerMapping和AnnotationMethodHandlerAdapter。 最后在controller类中调用service类进行业务处理，最终结合了mybaits操作修改了数据库。]]></content>
      <categories>
        <category>FrameWorks</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC]]></title>
    <url>%2F2016%2F07%2F16%2Fspringmvc%2F</url>
    <content type="text"><![CDATA[SpringMVC请求与controller映射SpringMVC通过DispatcherServlet 来处理请求信息，其中servlet-mapping配置指定了由Spring MVC 处理的请求的路径。下图中url-pattern被指定为/，这与/*有很大不同。 Tomcat在启动时会扫描web.xml文件，得到servlet的映射数据servletMappings，据此可以知道每个servlet处理的请求路径。通过分析源码，通常把路径4类： 以 / 结尾的。 path.endsWith(“/“) 以 . 开头的。 path.startsWith(“.”) 是否是 / path.equals(“/“) 以上3种之外的 上述4种映射处理后会被放入 wrapper中，这里Wrapper 代表一个 Servlet，它负责管理一个 Servlet，包括的 Servlet 的装载、初始化、执行以及资源回收，其中4类servlet对应的wrapper如下： /* 对应的Servlet会放在wildcardWrappers中 *. 会被放到extensionWrappers中 / 会被放到defaultWrapper中(缺省) 其他的映射都被放到exactWrappers中(精确匹配某一路径) 用户的请求过来时，会对请求的url进行匹配，匹配规则的先后顺序如下：1：精确匹配，使用contextVersion的exactWrappers2：前缀匹配，使用contextVersion的wildcardWrappers3：扩展名匹配，使用contextVersion的extensionWrappers4：使用资源文件来处理servlet，使用contextVersion的welcomeResources属性，这个属性是个字符串数组5：使用默认的servlet，使用contextVersion的defaultWrapper 下面我们继续分析对于某个具体的请求(如http://ip:port/contextPath/path)SpringMVC如何找到对应的Controller方法，即请求与Controller之间的映射关系。DispatcherServlet根据url得到对应的HandlerAdapter进行处理，处理过程中有几个重要的接口，HandlerMethodArgumentResolver、HandlerMethodReturnValueHandler。HandlerAdapter在处理每个请求时会实例化一个ServletInvocableHandlerMethod对象进行处理，处理请求时会根据ServletInvocableHandlerMethod的属性argumentResolvers（这个属性是它的父类InvocableHandlerMethod中定义的）进行处理，其中argumentResolvers属性是一个HandlerMethodArgumentResolverComposite类，这个类是实现了HandlerMethodArgumentResolver接口的类， 处理响应的时候，会根据ServletInvocableHandlerMethod的属性returnValueHandlers进行处理，returnValueHandlers属性是一HandlerMethodReturnValueHandlerComposite类，这个类是实现了HandlerMethodReturnValueHandler接口的类，这2个属性都在ServletInvocableHandlerMethod实例化的时候被赋值（通过HandlerAdapter的属性进行赋值），HandlerAdapter的相关属性是在HandlerAdapter进行实例化由Spring容量注入。 在常见的注解中，使用@ResponseBody注解的话最终返回值会被RequestResponseBodyMethodProcessor类处理，该类同时实现了HandlerMethodReturnValueHandler和HandlerMethodArgumentResolver这两个接口，所以它支持的请求类型是Controller方法参数中带有@RequestBody注解，支持的响应类型是Controller方法带有@ResponseBody注解，其他常用的HandlerMethodArgumentResolver实现类如下： 1.RequestParamMethodArgumentResolver 支持带有@RequestParam注解的参数或带有MultipartFile类型的参数 2.RequestParamMapMethodArgumentResolver 支持带有@RequestParam注解的参数 &amp;&amp; @RequestParam注解的属性value存在 &amp;&amp; 参数类型是实现Map接口的属性 3.PathVariableMethodArgumentResolver 支持带有@PathVariable注解的参数 且如果参数实现了Map接口，@PathVariable注解需带有value属性 4.MatrixVariableMethodArgumentResolver 支持带有@MatrixVariable注解的参数 且如果参数实现了Map接口，@MatrixVariable注解需带有value属性 5.RequestResponseBodyMethodProcessor 方法参数中带有@RequestBody注解 6.ServletRequestMethodArgumentResolver 参数类型是实现或继承或是WebRequest、ServletRequest、MultipartRequest、HttpSession、Principal、Locale、TimeZone、InputStream、Reader、HttpMethod这些类。 7.ServletResponseMethodArgumentResolver 参数类型是实现或继承或是ServletResponse、OutputStream、Writer这些类 8.RedirectAttributesMethodArgumentResolver 参数是实现了RedirectAttributes接口的类 9.HttpEntityMethodProcessor 参数类型是HttpEntity 常用的HandlerMethodReturnValueHandler实现类如下： 1.ModelAndViewMethodReturnValueHandler 返回值类型是ModelAndView或其子类 2.ModelMethodProcessor 返回值类型是Model或其子类 3.ViewMethodReturnValueHandler 返回值类型是View或其子类 4.HttpHeadersReturnValueHandler 返回值类型是HttpHeaders或其子类 5.ModelAttributeMethodProcessor 返回值有@ModelAttribute注解 6.ViewNameMethodReturnValueHandler 返回值是void或String SpringMVC中将一个类添加@Controller以表示该类是一个controller，其他常用的注解如下： 1.@RequestMapping 用来标记请求的路径，它可以标记在类上面，也可以标记在方法上，当方法上和类上都标记了@RequestMapping的时候，那么对应的方法对应的Url就是类上的加方法上的。在RequestMapping中还可以指定一个属性method，其主要对应的值有RequestMethod.GET和RequestMethod.POST，@RequestMapping中还有一个属性params，可以通过该属性指定请求参数中必须包含某一参数，或必须不包含某一参数，或某参数的值必须是什么，以此来缩小指定的映射范围。 2.@PathVariable 可以标记在方法的参数上，利用它标记的参数可以利用请求路径传值，下面是一个具体的例子 @RequestMapping(value=”/comment/{blogId}”, method=RequestMethod.POST) public void comment(Comment comment,@PathVariable int blogId, HttpSession session, HttpServletResponse response) throws IOException } 3.@RequestParam 用来给参数传值的，但是它是从头request的参数里面取值，相当于request.getParameter(“参数名”)方法。它的取值规则跟@PathVariable是一样的，当没有指定的时候，默认是从request中取名称跟后面接的变量名同名的参数值，当要明确从request中取一个参数的时候使用@RequestParam(“参数名”)。 4.返回值 返回一个ModelAndView，其中Model是一个Map，里面存放的是一对对的键值对，其可以直接在页面上使用，View是一个字符串，表示的是某一个View的名称 返回一个字符串，这个时候如果需要给页面传值，可以给方法一个Map参数，该Map就相当于一个Model，往该Model里面存入键值对就可以在页面上进行访问了 返回一个Model也就是一个Map，这个时 返回一个Model也就是一个Map，这个时候将解析默认生成的view name 任何其他类型的对象。这个时候就会把该方法返回类型对象当做返回Model模型的一个属性返回给视图使用，这个属性名称可以通过在方法上给定@ModelAttribute注解来指定，否则将默认使用该返回类名称作为属性名称。 5.@SessionAttributes 只能声明在类上，而不能声明在方法上，表示模型对象的特定属性具有 Session 范围的作用域 如：@SessionAttributes(types = {User.class,Dept.class},value={“attr1”,”attr2”})]]></content>
      <categories>
        <category>FrameWorks</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis]]></title>
    <url>%2F2016%2F07%2F16%2Fmybatis%2F</url>
    <content type="text"><![CDATA[MybatisMyBatis是支持普通SQL查询和高级映射的优秀持久层框架。它消除了几乎所有的JDBC代码和参数的手工设置以及对结果集的检索。MyBatis可以使用简单的XML或注解用于配置和原始映射，将接口和Java的POJO映射成数据库中的记录。MyBatis的应用程序都以一个SqlSessionFactory对象的实例为核心，它是SqlSessionFactoryBuilder对象通过配置文件Configuration类实例中来构建SqlSessionFactory对象，在使用时常通过Spring来集成和整合，下面是SqlSessionFactory的基本配置文件。可以看出，sqlSessionFactory被注册为spring容器中的bean，配置了使用的数据源，还有mybatis配置文件的位置、mapper xml文件的位置。sqlSessionFactory主要用来产生sqlSession，而sqlSession在Spring中使用了它的实现类sqlSessionTemplate，还定义了mapper接口的包路径，这里配置的MapperScannerConfigurer会将basePackage里的mapper接口注册为spring容器中的bean，并同时注入sqlSessionTemplate到mapper接口对象中，否则需要单独定义每一个mapper接口的bean。具体的Spring配置如下：由上面分析可以看出，sqlSessionFactory的产生流程如下：首先sqlSessionFactoryBean根据mybatis配置文件构造出configuration对象，.然后通过sqlSessionFactoryBuilder的build方法构造出一个sqlSessionFactory实例，sqlSession的产生是通过sqlSessionFactory创建了它的实现类sqlSessionTemplate。 下面继续分析Mybatis中mapper接口，通常在程序中我们通过如下方式使用mapper：在上面的spring配置中，将basePackage里的mapper接口注册为spring容器中的bean，在session调用getMapper时，扫描basePackage内的所有mapper接口并将这些bean设置为MapperFactoryBean.class，还添加了sqlSessionTemplate对象的引用。所以mapper对象由MapperFactoryBean来创建，在调用SqlSessionTemplate.getMapper时会调用MapperRegistry的getMapper方法，进而又通过了MapperProxyFactory对象创建mapper对象，MapperRegistry还记录了mapper接口和MapperProxyFactory对象的映射关系。MapperProxy类实现了InvocationHandler接口，mapper对象是其实是实现了对应mapper接口的动态代理对象，对mapper接口方法的调用都会调用代理对象的invoke方法，mapper对象的创建流程如下图：所以mybatis整合spring时，先通过SqlSessionFactoryBean创建了SqlSessionFactory，SqlSessionFactory创建了sqlSession，然后通过MapperFactoryBean生成了mapper对象，mapper对象的创建使用了java动态代理，mapper接口方法的调用都在代理对象的invoke方法中完成。 下面继续分析一条sql语句的执行过程：在getMapper方法得到mapper对象后，调用接口相关的语句时，经过上面的分析会调用MapperProxy对象的invoke方法(每一个MapperProxy对应一个dao接口)，然后会触发MapperMethod调用excute方法，该方法会根据根据类型去选择到底执行sqlSession中的哪个方法（insert、update、delete、select），然后执行相应的SqlSession的CRUD方法，之后会执行Excutor的doQueryQ方法，最后一步一步的封装最终通过PreparedStatement处理相关sql语句，然后执行结果逐步返回给sqlsession。最后在Mapper的的映射文件…Maper.xml文件中有很多动态sql语句，大大减少了sql语句拼接的复杂度，主要有insert、update、delete、select、if、choose、when、otherwise、where、set、foreach、trim等标签，具体的使用可参考帮助文档。 MyBatis的动态sql语句http://www.mybatis.org/mybatis-3/zh/dynamic-sql.html。]]></content>
      <categories>
        <category>FrameWorks</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Proxy]]></title>
    <url>%2F2016%2F07%2F16%2Fproxy%2F</url>
    <content type="text"><![CDATA[Java动态代理 动态代理模式是一种常用的设计模式，被广泛用于Spring，Mybatis，Hibernate等框架中。由于静态代理每一个代理类在编译之后都会生成一个class文件，代理类所实现的接口和所代理的方法都被固定，所以会导致系统中的类个数急剧增加，而动态代理可以让系统能够根据实际需要来动态创建代理类，让同一个代理类能够代理多个不同的真实主题类而且可以代理不同的方法。其中主要的类有Proxy、InvocationHandler。 Proxy中主要的方法如下： public static Class&lt;?&gt; getProxyClass(ClassLoader loader,Class&lt;?&gt;… interfaces):该方法用于返回一个Class类型的代理类，在参数中需要提供类加载器并需要指定代理的接口数组（与真实主题类的接口列表一致）。 public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[]interfaces, InvocationHandler h):该方法用于返回一个动态创建的代理类的实例，方法中第一个参数loader表示代理类的类加载器，第二个参数interfaces表示代理类所实现的接口列表（与真实主题类的接口列表一致），第三个参数h表示所指派的调用处理程序类。 InvocationHandler接口中最重要的一个方法： public Object invoke(Objectproxy, Method method, Object[] args):该方法用于处理对代理类实例的方法调用并返回相应的结果，当一个代理实例中的业务方法被调用时将自动调用该方法。invoke()方法包含三个参数，其中第一个参数proxy表示代理类的实例，第二个参数method表示需要代理的方法，第三个参数args表示代理方法的参数数组。 动态代理类需要在运行时指定所代理真实主题类的接口，客户端在调用动态代理对象的方法时，调用请求会将请求自动转发给InvocationHandler对象的invoke()方法，由invoke()方法来实现对请求的统一处理。下面是一个具体的例子： 程序中有Subject接口和其具体实现类RealSubject，方法为doSomething。 首先通过InvocationHandler创建调用处理器，然后Proxy的静态方法根据接口的classloader和interface产生动态代理对象，它继承Proxy类实现Subject接口，实现的Subject的方法实际调用处理器的invoke方法，而invoke方法利用反射调用的是被代理对象的方法（Object result=method.invoke(proxied,args)）。然而 java动态代理也有一个缺点，由于java动态代理本质是对interface的代理，对于未实现接口的类无法进行代理，而cglib没有这个限制，下面是cglib的一些简介。 cglib是针对类来实现代理的，他的原理是对指定的目标类生成一个子类，并覆盖其中方法实现增强，其本质采用的是继承，示例如下：在获取动态代理对象时，enhancer.setSuperclass(object.getClass())表明生产的代理对象为被代理类的子类，当调用代理类方法时通过intercept调用了父类的相应方法并传递了相应的参数。虽然cglib不需要接口，但对于final类，无法生成代理类，另一方面其底层使用了asm产生字节码，在android中dalvik虚拟机不支持此字节码，所以android中无法使用cglib。]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Json]]></title>
    <url>%2F2016%2F07%2F16%2FJson%2F</url>
    <content type="text"><![CDATA[初识Json在对接第三方过程中，经常遇到格式不对和校验失败的问题，大多数是第三方返回的json存在各种问题，整理一下json的格式和常见用法。首先，json 数据的书写格式是：名称/值对，和java中map很类似，但它的key只能用string，如”firstName” : “John”，json值可以为：数字（整数或浮点数），字符串（在双引号中），逻辑值（true 或 false），数组（在方括号中），对象（在花括号中），null。JSON 对象在花括号中书写，对象可以包含多个名称/值对，如：{ “firstName”:”John” , “lastName”:”Doe” }JSON 数组在方括号中书写，数组可包含多个对象，如：所以Json对象中，可以嵌套很多层，形成复杂的结构。json对象的创建如下：结果如下：另外，Json和java中的容器也可以相互转换，如下所示：结果如下：以上是json的格式和常见的用法，复杂的json也是通过多层嵌套组合而成。]]></content>
      <categories>
        <category>Language</category>
      </categories>
      <tags>
        <tag>Json</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM Tools]]></title>
    <url>%2F2016%2F07%2F14%2Fjvmtools%2F</url>
    <content type="text"><![CDATA[JVM性能监控工具jdk中常见的命令有如下几种： 名称 说明 jps JVM Process Status Tool，显示指定系统内所有的HotSpot虚拟机进程 jstat JVM Statistics Monitoring Tool，用于收集HotSpot虚拟机各方面的运行数据 jinfo Configuration Info for Java，显示虚拟机配置信息 jmap Memory Map for Java，生成虚拟机的内存转存储快照（heapdump文件） jhat VM Heap Dump Browser，用于分析heapdump文件，它会建立一个HTTP/HTML服务器，让用户可以在浏览器上查看分析结果 jstat Stack Trace for Java，显示虚拟机的线程快照 1.jps列出正在运行的虚拟机进程，并显示虚拟机执行主类（Main Class，main()函数所在的类）名称以及这些进程的本地虚拟机唯一ID（Local Virtual Machine Identifier，LVMID）,LVMID与操作系统的进程ID是一致的。jps命令格式：jsp [options] [hostid]jps -l 选项 作用 -q 只输出LVMID，省略主类的名称 -m 输出虚拟机进程启动时传递给主类main()函数的参数 -l 输出主类的全名，如果进程执行的是jar包，输出Jar路径 -v 输出虚拟机进程启动时JVM参数 2.jstat用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。jstat命令格式：jstat [option vmid [ interval[s|ms] [count] ] ]jstat –gc 2764 250 20 选项 作用 -class 监视类装载，卸载数量、总空间以及类装载所耗费的时间 -gc 监视Java堆情况，包括Eden区、两个survivor区、老年代、永久代等的容量、已用空间、GC时间合计等信息 -gccapacity 监视内容与-gc基本相同，但输出主要关注Java堆各个区域使用到的最大、最小空间 -gcutil 监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比 -gccause 与-gcutil功能一样，但是会额外输出导致上一次GC产生的原因 -gcnew 监视新生代GC情况 -gcnewcapacity 监视内容与-gcnew基本相同，输出主要关注使用到的最大、最小空间 -gcold 监视老年代GC状况 -gcoldcapacity 监视内容与-gcold基本相同，输出主要关注使用到的最大、最小空间 -gcpermcapacity 输出永久代使用到的最大、最小空间 -compiler 输出JIT编译器编译过的方法、耗时等信息 -printcompilation 输出已经被JIT编译的方法 3.jinfo实时地查看和调整虚拟机各项参数。jinfo -flag MaxHeapSize 3850 选项 作用 -flag 输出指定虚拟机参数，如jinfo -flag MaxHeapSize pid -sysprops 输出虚拟机进程的System.getProperties()的内容 -flag[+-] name 修改虚拟机参数值 -flag name=value 同上 4.jmap命令用于生成堆转储快照（一般称为heapdump或dump文件），jmap的作用并不仅仅是为了获取dump文件，它还可以查询finalize执行队列、Java堆和永久代的详细信息，如果空间使用率、当前用的是哪种收集器等。jmap命令格式：jmap [option] vmidjmap -dump:format=b,file=tomcat.bin 3850 选项 作用 -dump 生成Java堆转储快照。格式为：-dump:[live, ]format=b, file=，其中live子参数说明是否只dump出存活的对象 -finalizerinfo 显示在F-Queue中等待Finalizer线程执行finalize方法的对象。只在Linux/Solaris平台下有效 -heap 显示Java堆详细信息，如使用哪种回收器、参数配置、分代状况等。只在Linux/Solaris平台下有效 -histo 显示堆中对象统计信息，包括类、实例数量、合计容量 -permstat 以ClassLoader为统计口径显示永久代内存状态。只在Linux/Solaris平台下有效 -F 当虚拟机进程对-dump选项没有响应时，可使用这个选项强制生成dump快照。只在Linux/Solaris平台下有效 5.jhat Sun JDK提供jhat（JVM Heap Analysis Tool）命令与jmap搭配使用，来分析jmap生成的堆转储快照。Jhat内置了一个微型的HTTP/HTML服务器。生产dump文件的分析结果后，可以在浏览器中查看。jhat tomcat.bin 6.jstackjstack（Stack Trace for Java）命令用于生产虚拟机当前时刻的线程快照（一般称为threaddump或者javacore文件）。线程快照就是当虚拟机内每一条线程正在执行的方法堆栈集合，生产线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致长时间等待等都是导致线程长时间停顿的常见原因。线程出现停顿的时候通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做些什么事情，或者等待着什么资源。jstack命令格式：jstack [option] vmidjstack -l 3845 选项 作用 -F 当正常输出的请求不被响应时，强制输出线程堆栈 -l 除堆栈外，显示关于锁的附加信息 -m 如果调用到本地方法的话，可以显示C/C++的堆栈 7.可视化监控工具JDK中除了提供大量的命令行工具外，还有两个功能强大的可视化工具：JConsole和VisualVM，这两个工具是JDK的正式成员。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadPoolExcutor]]></title>
    <url>%2F2016%2F06%2F22%2Fthreadpool%2F</url>
    <content type="text"><![CDATA[ThreadPoolExcutor入门线程池将任务的提交与任务的执行解耦开来，它对线程进行管理和调度，通过合理的设置能够避免创建过多的线程，提高资源利用率和系统吞吐量。java中线程池为ThreadPoolExecutor，通过不同的参数设置来实现不同的线程池机制。首先ThreadPoolExcutor继承自AbstractExecutorService，而AbstractExecutorService实现了ExecutorService接口，它最核心构造函数如下：123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125; 参数名 作用 corePoolSize 核心线程池大小 maximumPoolSize 最大线程池大小 keepAliveTime 线程池中超过corePoolSize数目的空闲线程最大存活时间；可以allowCoreThreadTimeOut(true)使得核心线程有效时间 TimeUnit keepAliveTime时间单位 workQueue 阻塞任务队列 threadFactory 新建线程工厂 RejectedExecutionHandler 当提交任务数超过maxmumPoolSize+workQueue之和时，任务会交给RejectedExecutionHandler来处理 线程处理、管理流程如下图：下面简单说明线程池在提交一个任务时的处理方法：1.当线程池小于corePoolSize时，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。2.当线程池达到corePoolSize时，新提交任务将被放入workQueue中，等待线程池中任务调度执行3.当workQueue已满，且maximumPoolSize&gt;corePoolSize时，新提交任务会创建新线程执行任务4.当提交任务数超过maximumPoolSize时，新提交任务由RejectedExecutionHandler处理5.当线程池中超过corePoolSize线程，空闲时间达到keepAliveTime时，关闭空闲线程6.当设置allowCoreThreadTimeOut(true)时，线程池中corePoolSize线程空闲时间达到keepAliveTime也将关闭 WorkQueue的类型主要分为了3类：1.直接提交。SynchronousQueue它将任务直接提交给线程而不保持它们。在此，如果不存在可用于立即运行任务的线程，则试图把任务加入队列将失败，因此会构造一个新的线程。此策略可以避免在处理可能具有内部依赖性的请求集时出现锁。直接提交通常要求无界 maximumPoolSizes或者可以拒绝的。当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。2.无界队列。使用无界队列（例如，不具有预定义容量的 LinkedBlockingQueue）将导致在所有 corePoolSize 线程都忙时新任务在队列中等待。这样，创建的线程就不会超过 corePoolSize。（因此，maximumPoolSize 的值也就无效了。）当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列；例如，在 Web 页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。3.有界队列。当使用有限的 maximumPoolSizes 时，有界队列（如 ArrayBlockingQueue、LinkedBlockingQueue、PriorityBlockingQueue）有助于防止资源耗尽，但是可能较难调整和控制。队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。如果任务频繁阻塞（例如，如果它们是 I/O 边界），则系统可能为超过您许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU 使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。 ThreadFactory每当线程池需要创建一个线程时，都会通过threadFactory的工厂方法newThreadFactory来创建一个新的、非守护线程，当然可以继承ThreadFactory来自定义创建的线程，设置线程的优先级、名字、增加日志等功能。 RejectedExecutionHandler当当提交任务数超过maximumPoolSize、队列已满时将采取拒绝策略，这将调用RejectedExecutionHandler的rejectedExecution方法，ThreadPoolExcutor 提供了4种预定义的拒绝策略： 在默认的 ThreadPoolExecutor.AbortPolicy 中，处理程序遭到拒绝将抛出运行时 RejectedExecutionException 在 ThreadPoolExecutor.CallerRunsPolicy 中，线程调用运行该任务的 execute 本身即在excute本身的线程中执行run方法。此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。3.在 ThreadPoolExecutor.DiscardPolicy 中，当前的任务将被抛弃。4.在 ThreadPoolExecutor.DiscardOldestPolicy 中，如果执行程序尚未关闭，则位于工作队列头部（注意优先级队列）的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程） Executors提供了几个常用的线程池配置方案：1.构造一个固定线程数目的线程池，配置的corePoolSize与maximumPoolSize大小相同，同时使用了一个无界LinkedBlockingQueue存放阻塞任务，因此多余的任务将存在再阻塞队列，不会由RejectedExecutionHandler处理12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 2.构造一个缓冲功能的线程池，配置corePoolSize=0，maximumPoolSize=Integer.MAX_VALUE，keepAliveTime=60s,以及一个无容量的阻塞队列 SynchronousQueue，因此任务提交之后，将会创建新的线程执行；线程空闲超过60s将会销毁12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 3.构造一个只支持一个线程的线程池，配置corePoolSize=maximumPoolSize=1，无界阻塞队列LinkedBlockingQueue；保证任务由一个线程串行执行123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 4.构造有定时功能的线程池，配置corePoolSize，无界延迟阻塞队列DelayedWorkQueue；有意思的是：maximumPoolSize=Integer.MAX_VALUE，由于DelayedWorkQueue是无界队列，所以这个值是没有意义的1234567891011121314public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125;public static ScheduledExecutorService newScheduledThreadPool( int corePoolSize, ThreadFactory threadFactory) &#123; return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory);&#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS, new DelayedWorkQueue(), threadFactory);&#125; 下面我们自定义写一个线程池：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.meituan.concurrent;import java.util.concurrent.*;import java.util.concurrent.atomic.AtomicLong;/** * Author:fuyang@meituan.com * Date:16/7/20 * Time:下午2:13 */public class ThreadPoolExecuotrTest extends ThreadPoolExecutor &#123; private final ThreadLocal&lt;Long&gt; startTime = new ThreadLocal&lt;Long&gt;(); private final AtomicLong executeTime = new AtomicLong(0); public ThreadPoolExecuotrTest(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, new MyThreadFactory(), new RejectHandler()); &#125; @Override protected void beforeExecute(Thread t, Runnable r) &#123; super.beforeExecute(t, r); System.out.println(Thread.currentThread().getName()+" before"); startTime.set(System.currentTimeMillis()); &#125; @Override protected void afterExecute(Runnable r, Throwable t) &#123; long endTime = System.currentTimeMillis(); executeTime.addAndGet(endTime - startTime.get()); System.out.println(Thread.currentThread().getName()+" after"); super.afterExecute(r, t); &#125; @Override protected void terminated() &#123; System.out.println("time " + executeTime.get()); super.terminated(); &#125; public static void main(String[] args) &#123; ThreadPoolExecuotrTest threadPoolExecuotrTest = new ThreadPoolExecuotrTest(2, 4, 10, TimeUnit.SECONDS, new LinkedBlockingDeque&lt;Runnable&gt;(2)); for (int i = 0; i &lt; 8; i++) &#123; threadPoolExecuotrTest.execute(new Runnable() &#123; public void run() &#123; try &#123; System.out.println(Thread.currentThread().getName() + " execute"); Thread.sleep(6000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; threadPoolExecuotrTest.shutdown(); &#125;&#125; 执行8次任务，那么线程池中达到最大线程数，队列也会打满，那么剩下的2个任务将会采取拒绝策略，我们复写了rejectExecution方法，将任务put阻塞提交到队列，所以所有的任务的都会执行：1234567891011121314151617181920package com.meituan.concurrent;import java.util.concurrent.RejectedExecutionHandler;import java.util.concurrent.ThreadPoolExecutor;/** * Author:fuyang@meituan.com * Date:16/7/20 * Time:下午3:23 */public class RejectHandler implements RejectedExecutionHandler &#123; public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; System.out.println("reject"); try &#123; executor.getQueue().put(r); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 执行结果如下：1234567891011121314151617181920212223242526272829Connected to the target VM, address: '127.0.0.1:54007', transport: 'socket'com.meituan.concurrent.MyThreadFactory-1 beforecom.meituan.concurrent.MyThreadFactory-4 beforecom.meituan.concurrent.MyThreadFactory-1 executerejectcom.meituan.concurrent.MyThreadFactory-3 beforecom.meituan.concurrent.MyThreadFactory-3 executecom.meituan.concurrent.MyThreadFactory-2 beforecom.meituan.concurrent.MyThreadFactory-4 executecom.meituan.concurrent.MyThreadFactory-2 executecom.meituan.concurrent.MyThreadFactory-4 aftercom.meituan.concurrent.MyThreadFactory-2 aftercom.meituan.concurrent.MyThreadFactory-1 aftercom.meituan.concurrent.MyThreadFactory-3 aftercom.meituan.concurrent.MyThreadFactory-2 beforecom.meituan.concurrent.MyThreadFactory-2 executerejectcom.meituan.concurrent.MyThreadFactory-4 beforecom.meituan.concurrent.MyThreadFactory-4 executecom.meituan.concurrent.MyThreadFactory-3 beforecom.meituan.concurrent.MyThreadFactory-3 executecom.meituan.concurrent.MyThreadFactory-1 beforecom.meituan.concurrent.MyThreadFactory-1 executeDisconnected from the target VM, address: '127.0.0.1:54007', transport: 'socket'com.meituan.concurrent.MyThreadFactory-4 aftercom.meituan.concurrent.MyThreadFactory-3 aftercom.meituan.concurrent.MyThreadFactory-2 aftercom.meituan.concurrent.MyThreadFactory-1 aftertime 48016 另外，线程池中shutdown方法通过interrupt中断线程，设置为shutdown状态，但只能中断空闲线程，阻止继续提交任务，队列中的任务仍会执行，shutdownNow会interrupt所有的线程，设置为stop 状态，但不能保证所有的线程马上结束（参考interrupt作用），队列中的任务也会丢弃不执行。awaitTermination阻塞等待shutdown后线程结束。 一般来说，最好使用Executors提供的4种线程池，除非有特别的需求可以定义独特的线程池，线程池的大小确定是重点，线程池过大导致竞争激烈，线程池过小吞吐量较低。所以在任务量较少可以使用无界的队列，任务量很大使用有介的队列防止OOM，也有一种通用的计算方法：N（thread）＝N（cpu）＊U（cpu）（1+W / C），其中分别为cpu数量，cpu利用率，等待时间和计算时间，最大线程数一般设为2N+1，N是CPU核数。当然线程池大小还受到内存，io等其他因素影响。 最后注意线程间的依赖，在有界线程池中容易产生死锁现象。 线程池这部分知识感觉有些复杂，掌握起来有些困难，底层一些机制源码不太容易理解。]]></content>
      <categories>
        <category>Concurrent</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hashmap]]></title>
    <url>%2F2016%2F06%2F18%2Fhashmap%2F</url>
    <content type="text"><![CDATA[Hashmap线程安全性分析java中通过锁实现同步的方式主要有2种：通过synchronized关键字和显示的lock。java中map可以快速定位某个元素，查询速度比数组、list都要快，所以广泛应用于java开发中。其底层数据结构也较为简单，本质是结合了数组和链表，即Entry数组。但hashmap并不是线程安全的，在多线程高并发环境下会存在很多问题，其中出现在问题往往出现在put操作上，我们先看看put操作的源码： put操作首先通过key的hashcode定位到数组某一个位置，然后结合equals方法查找是否存在相同的key，若存在直接修改value，否则addEntry增加新节点addentry方法中会检查map size是否超过规定的值，若超过需要扩充容量，即resize操作resize过程中会通过transfer方法会将数据转移到新的位置 现在我们分析一下，这个过程中可能存在的问题。首先，在不同的线程中，同时操作了同一个对象，按照java内存模型来理解，各个线程中有自己的工作内存，并且该内存中有主存中的副本，这些副本之间不能直接进行通信，必须依靠主内存中的值来通信，所以下面就会出现很多问题。 1.丢失put的修改假设2个线程都同时在一个位置put相同的key，该key并不存在，所以2个线程中都会执行addEntry方法的new Entry (hash, key, value, e)，结果新的节点都指向了e，所以一个线程put后读取的时候可能读取的值并不相同。 2.put过程导致读取null值若在put操作后导致了resize操作，在transfer中有一行代码src[j]=null，即把旧数组设置为null垃圾回收，在transfer执行结束前，另一线程读取的还是旧的数组，可能存在读取某个存在key为null 3.transfer导致死循环下面举一个简单的例子12345678910111213141516public static void main(String[] args) &#123; HashMap&lt;Integer,String&gt; map = new HashMap&lt;Integer,String&gt;(2，0.75f); map.put(5， "C"); new Thread("Thread1") &#123; public void run() &#123; map.put(7, "B"); System.out.println(map); &#125;; &#125;.start(); new Thread("Thread2") &#123; public void run() &#123; map.put(3, "A); System.out.println(map); &#125;; &#125;.start(); &#125; map在存放第二个key的时候将会扩容，这将导致resize操作， 假设在两个线程resize前，数组内容如下： 第一个线程由于某个原因被挂起，第二个线程先transfer完成，现在第一个线程将要执行transfer操作 在第一个循环执行后，线程1的结构将会变成这样 然后继续执行一个循环后，如下所示 最后一个循环执行后，e将为null，此时的结构如下： 而此时map中entry数组的第三个位置出现了环，如果get方法调用是刚好定位到entry[3]如key为11时，将陷入无限循环。所以hashmap需要使用一种线程安全的方式使用，当前常见的方案有：1.使用hashtable，但现在很少使用2.使用Collections.synchronizedMap包装hashmap，在同步块synchronized或lock中使用map3.使用ConcurrentHashMap，它实质是一种分段的hashtable，内部是一个segment数组，没一个segment类似一个hashtable，这样对每一个segment进行分段加锁，而且只有put操作是加锁的，get操作大部分情况下不加锁，除非读取到null，这样保证了map并发时的高效率。]]></content>
      <categories>
        <category>Concurrent</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>DataStructure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Thread]]></title>
    <url>%2F2016%2F05%2F22%2Fthread%2F</url>
    <content type="text"><![CDATA[Thread认识Thread被广泛用于java并发编程中，在学习thread用法前，我们需要先了解一下线程的状态。操作系统中，线程的状态有新建、就绪、运行、阻塞、结束，在java中我们分别称之为new、runnable、blocked、waitting、time_waiting、dead。下图展示了thread从创建到消亡的过程： 从上图看出，thead在创建后并不会立即进入就绪状态，需要分配一些资源（程序计数器、Java栈、本地方法栈等），当线程进入就绪状态后也不会立即执行，它需要等到分配cpu时间片后才能运行。线程在执行中也可能由多个原因导致线程无法执行下去，如线程睡眠、被其他线程强占、io阻塞、等待锁释放等，此时线程就会从运行状态转移到其他状态。当线程执行结束或被中断，那么线程随后将会消亡。 虽然线程能够使得任务能够并发执行，能在一定条件下提高执行效率。但线程在使用时也是有一定的代价，线程的创建需要额外的内存，线程在执行时也不会一帆风顺，线程间的切换需要保存线程的上下文信息，这无疑会增加系统的开销。过多的线程必定会导致内存使用增加，线程间切换也会增加系统开销，导致资源利用率降低，所以设置合理的线程数量很重要，在使用多线程时常常使用threadpool对线程进行管理，线程池能合理的控制线程数量，对线程进行复用而不是不断创建新的线程，可以多多阅读threadpoolexcutor相关知识。 下面我们了解一下thread中常见的方法，首先在使用thread时一般继承thread或者实现runnale，这两种方式效果一致，通过查看源码可知thread本身实现了runnable接口，其中最核心的方法是run方法，下面我们结合线程的状态转移图介绍thread中常见的方法： 1.start 启动一个线程，等待分配内存等资源后，进入runnable状态。2.run 在runnable状态获取分配的cpu时间片后进入运行状态，在run方法中执行线程任务，但需要注意直接使用run方法并不能在另一个线程执行任务，必须调用start方法后，等待操作系统分配资源和cpu后才能在另一个线 程中执行任务3.yield 让当前线程交出CPU权限，让CPU去执行其他相同优先级的线程，但yield不能控制具体的交出CPU的时间，执行的其它线程也不完全由优先级决定，它由底层操作系统调度来决定，yield的效果使得当前线程在交出 cpu时间后回到runnable状态，而不是blocked。4.sleep 让线程睡眠一定时间，交出CPU，让CPU去执行其他的任务，此时线程处于blocked状态。5 join 使当前线程等待下一个线程执行完（无参数）或等待一定时间后（带时间参数，join线程未执行完，达到规定时间）后继续执行，可以用来处理线程间通信（一个线程等待另一个线程执行结果的情况），join方法中实质是调用了wait方法。join方法也使得线程进入blocked状态。6.interrupt 使得线程中断。单独调用interrupt方法可以使得处于阻塞状态（sleep、wait、join）的线程抛出一个异常，它可以用来中断一个正处于阻塞状态的线程；另外，通过interrupt方法来停止正在运行的线程。但它不 能停止正在运行处于非阻塞状态的线程，也不能中断某些阻塞状态（synchronized、lock、阻塞io）等。而且在sleep、wait、join等阻塞状态时引发中断会抛出InterruptedException，并且会由jvm清除中断状态，所以需要在 catch块中使用interrupt重置中断状态。7.stop、destroy 用于终止线程执行废弃的方法，不建议使用，可以采用标记法、中断法。8.priority、daemon 设置线程的优先级和设置守护进程。线程的优先级并不保证线程一定会被优先调度，操作系统应该是基于概率的调度，优先级高被调度的可能性大。守护线程用于一些后续处理工作，如gc线程，守护线 程在所有工作线程执行完后会结束而不管自己是否执行完，所以一般的费事任务不要设置守护线程，守护线程主要用于一些清理工作。9.需要注意的几个点yield让出cpu时间后处于runnable状态，并且让出的具体时间、执行线程的优先级和操作系统调度有关。wait和sleep有很大区别：首先wait是object的方法，sleep是thread的方法，其次重要的一点是wait会释放当前线程持有的锁，所以wait notify必须在同步块（synchronized、lock）中使用，notify会 唤醒某一个等待同一个锁的线程，其他的锁仍然在wait处阻塞，notifyall唤醒所有等待同一锁的线程，但它们需要对该锁进行竞争；而sleep不释放锁，并且sleep方法可能抛出异常。interrupt用于线程中断，对于sleep、join、wait等阻塞方法会抛出InterruptedException异常，并且会清楚中断状态，如果程序中需要使用中断状态的话必须在捕获异常后重新设置中断状态，对于不可中断阻塞如锁 （lock、synchronized），io阻塞（read、accept、select）仅仅设置了线程的中断状态并不会中断线程，所以这时对于不可中断io阻塞可以复写interrupt方法，直接把io流close然后中断线程；对于锁就只能等待其他线程释放锁。]]></content>
      <categories>
        <category>Concurrent</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git]]></title>
    <url>%2F2016%2F05%2F16%2Fgit%2F</url>
    <content type="text"><![CDATA[Git入门Git是一个分布式的版本控制系统，相对于集中式版本控制系统，git有很多的优势。 它不会依赖中央服务器，即使中央服务器发生故障，也能从任何客户端库可以复制回服务器。git有如下几个特点：自由和开放源码、快速和小、隐式备份、安全、不需要强大的硬件、更简单的分支。git中重要的几个概念：工作区、暂存区、版本库。工作区简单来说是指我们电脑上的能够看见的文件目录，可以对文件进行修改。版本库是指本地的Repository，项目目录中有.git目录这就是版本库存放了git的信息，如git分支和head指针等。暂存区stage指的是把用户文件修改暂存起来，等待提交修改，这样git可以只提交部分修改的信息。Git的基本工作流程如下：第1步：修改文件的工作目录。第2步：将这些文件添加到暂存区第3步：执行commit操作，提交操作后，它永久地存储更改的Git仓库 当我们使用git往往是多人合作，所以需要一个git远程库，并与之建立关联。若我们本地有一个版本库需要添加一个远程库与之关联，则在gittub建立一个Repository，然后在本地某个目录下使用git init命令建立一个git版本库，然后使用git remote add origin url（git远程库地址） 与远程库建立连接，最后使用git push origin master把本地master分支与远程的master分支建立关联。若远程版本库存在，需要克隆或拷贝到本地git库，则可以使用git clone url，这样远程库的代码被拷贝到本地并建立了关联。下面是git的一些常用命令： 添加到暂存区：git add 我们在工作去修改了某个文件后，在提交修改前需要把修改的文件加入暂存区，首先可以用git status查看状态，也可以使用git diff 查看不同之处，使用 git dif －－cached 可以查询添加到暂存区的改动： 可以使用git reset HEAD －－filename取消已加入暂存区的文件： 然后使用git add filename 和git commit －m ＋ 描述或 git commit －am ＋描述 提交修改，效果如下 git log可以查看修改的历史信息，使用git reset –hard HEAD^可以回退到上一个版本，使用git reset –hard HEAD~100回退到前100个版本，若回退后又想回退到最新版本，可以使用git reflog查看版本号，然后回退到某一版本号，效果如下： 当修改了工作区的文件后，没有提交暂存区，想要恢复到修改前的文件，可以修改文件也可以回退到上一个版本，也可以使用git checkout －－ filename，效果如下： git rm filename会删除暂存区和本地工作目录下的文件，若只删除暂存区的文件则使用git rm －－cached filename，git mv filename newfile会重命名文件，其本质是先删除暂存区文件然后执行文件重命名最后使用git add这三步操作,改变名称后commit就可以了。 git中创建分支使用git branch branch_name ，然后使用git checkout branch_name切换分支，也可以一步到位git checkout －b branch_name，分支合并使用git merge branch_name，在分支合并是可能存在冲突问题，如在master分析修改文件，然后另一分支也修改，合并是会产生冲突，需要手动修改后重新提交，如下： 我们修改后的代码需要提交到远程库，则使用git push origin local_branch : remote_branch 若省略远程分支则默认是与当前的分支同名的分支， 如下： 如果在push前有其他用户已经提交了修改则会产生冲突，这时需要先pull远程库分支与本地分支合并并解决分支冲突问题，然后在commit，最后在push到远程分支，如下： pull的使用：git pull origin remote_branch :local_branch，若省略了本地分支则默认是当前的分支，pull本质是先git fetch origin操作，然后git merge origin／分支名，先feych再merge。 因此：多人协作工作模式一般是这样的： 首先，可以试图用git push origin branch-name推送自己的修改. 如果推送失败，则因为远程分支比你的本地更新早，需要先用git pull试图合并。 如果合并有冲突，则需要解决冲突，并在本地提交。再用git push origin branch-name推送 当正在修改文件时，需要解决另一个需要及时处理的问题，而当前开发没有完成，则可以使用git stash将当前的状态保存在栈中，带紧急任务完成后，使用git stash list查看栈中情况，然后使用git stash pop（弹出并删除栈顶），或git stash apply不删除栈顶状态。 最后，git远程库，本地库，暂存区交互情况如下：]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
</search>
